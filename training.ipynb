{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, make_scorer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>year</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>...</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>statusId</th>\n",
       "      <th>circuit_country</th>\n",
       "      <th>constructor_position</th>\n",
       "      <th>constructor_wins</th>\n",
       "      <th>constructor_nationality</th>\n",
       "      <th>driver_nationality</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>results_positionOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.264318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>881</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.224938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>882</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.395410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187334</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>883</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.495754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186830</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>884</td>\n",
       "      <td>2013</td>\n",
       "      <td>-0.691174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194470</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>567</td>\n",
       "      <td>1976</td>\n",
       "      <td>1.281412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>-0.955050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>571</td>\n",
       "      <td>1976</td>\n",
       "      <td>-0.613072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645484</td>\n",
       "      <td>1.129065</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>563</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.861440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>-0.595194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>574</td>\n",
       "      <td>1976</td>\n",
       "      <td>-0.072666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>566</td>\n",
       "      <td>1976</td>\n",
       "      <td>1.491559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>-0.955050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      raceId  year  circuitId  weather_warm  weather_cold  weather_dry  \\\n",
       "0        880  2013  -1.264318           1.0           0.0          0.0   \n",
       "1        881  2013  -1.224938           0.0           0.0          1.0   \n",
       "2        882  2013  -1.395410           1.0           0.0          0.0   \n",
       "3        883  2013  -1.495754           1.0           0.0          0.0   \n",
       "4        884  2013  -0.691174           1.0           0.0          0.0   \n",
       "...      ...   ...        ...           ...           ...          ...   \n",
       "2499     567  1976   1.281412           1.0           0.0          0.0   \n",
       "2500     571  1976  -0.613072           0.0           0.0          1.0   \n",
       "2501     563  1976   0.861440           1.0           0.0          0.0   \n",
       "2502     574  1976  -0.072666           1.0           0.0          0.0   \n",
       "2503     566  1976   1.491559           0.0           0.0          1.0   \n",
       "\n",
       "      weather_wet  weather_cloudy  driverId  constructorId  ...  milliseconds  \\\n",
       "0             0.0             0.0 -0.671359      -0.965034  ...      0.176079   \n",
       "1             1.0             1.0 -0.671359      -0.965034  ...      1.000000   \n",
       "2             0.0             0.0 -0.671359      -0.965034  ...      0.187334   \n",
       "3             0.0             0.0 -0.671359      -0.965034  ...      0.186830   \n",
       "4             0.0             0.0 -0.671359      -0.965034  ...      0.194470   \n",
       "...           ...             ...       ...            ...  ...           ...   \n",
       "2499          0.0             0.0  0.129289      -0.955050  ...      1.000000   \n",
       "2500          0.0             0.0  0.645484       1.129065  ...      1.000000   \n",
       "2501          0.0             0.0  0.129289      -0.595194  ...      1.000000   \n",
       "2502          0.0             0.0  0.129289       0.043700  ...      1.000000   \n",
       "2503          0.0             0.0  0.129289      -0.955050  ...      1.000000   \n",
       "\n",
       "      statusId  circuit_country  constructor_position  constructor_wins  \\\n",
       "0            1                2                   6.0         -0.310902   \n",
       "1            0               17                   7.0         -0.310902   \n",
       "2            1                9                   5.0         -0.310902   \n",
       "3            1                5                   6.0         -0.310902   \n",
       "4            1               28                   6.0         -0.310902   \n",
       "...        ...              ...                   ...               ...   \n",
       "2499         0               10                  17.0         -0.310902   \n",
       "2500         0               21                  10.0         -0.310902   \n",
       "2501         0               28                  15.0         -0.310902   \n",
       "2502         0               34                  14.0         -0.310902   \n",
       "2503         0               29                  17.0         -0.310902   \n",
       "\n",
       "      constructor_nationality  driver_nationality  driver_wins  driver_age  \\\n",
       "0                    0.105238                  33    -0.310902    0.666667   \n",
       "1                    0.105238                  33    -0.310902    0.666667   \n",
       "2                    0.105238                  33    -0.310902    0.666667   \n",
       "3                    0.105238                  33    -0.310902    0.666667   \n",
       "4                    0.105238                  33    -0.310902    0.666667   \n",
       "...                       ...                 ...          ...         ...   \n",
       "2499                 0.105238                  33    -0.310902    0.541667   \n",
       "2500                 0.105238                  29    -0.310902    0.791667   \n",
       "2501                 0.105238                  28    -0.310902    0.583333   \n",
       "2502                 0.076599                   2    -0.310902    0.375000   \n",
       "2503                 0.105238                  38    -0.310902    0.625000   \n",
       "\n",
       "      results_positionOrder  \n",
       "0                         9  \n",
       "1                        17  \n",
       "2                         5  \n",
       "3                        10  \n",
       "4                         8  \n",
       "...                     ...  \n",
       "2499                     20  \n",
       "2500                     20  \n",
       "2501                     20  \n",
       "2502                     14  \n",
       "2503                     20  \n",
       "\n",
       "[2504 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data_new/train_pre.csv').drop_duplicates()\n",
    "df_test = pd.read_csv('./data_new/test_pre.csv').drop_duplicates()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customCrossValidation():\n",
    "\n",
    "    def split(self, x):\n",
    "        indices = []\n",
    "        for i in range(5):\n",
    "            years = x['year'].unique()\n",
    "            np.random.shuffle(years)\n",
    "            val_years = years[:6]\n",
    "            train_years = years[6:]\n",
    "\n",
    "            indices.append((x[x['year'].isin(train_years)].index, x[x['year'].isin(val_years)].index))\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression() :\n",
    "    \n",
    "    def my_scoring(self, model, x, y):\n",
    "\n",
    "        precision = 0\n",
    "        accuracy = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "        for i in x['raceId'].unique():\n",
    "            prediction_df = pd.DataFrame(model.predict(x[x['raceId'] == i]), columns = ['results'])\n",
    "            # print(np.unique(np.round(prediction_df['results'].values)))\n",
    "            Y_test = y[x[x['raceId'] == i].index]\n",
    "\n",
    "            \n",
    "            prediction_df['podium'] = Y_test.reset_index(drop = True)\n",
    "            prediction_df['actual'] = prediction_df.podium.map(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "            prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "            prediction_df.reset_index(inplace = True, drop = True)\n",
    "            prediction_df['predicted'] = prediction_df.index\n",
    "            prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x in [0, 1, 2] else 0)\n",
    "\n",
    "            precision += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "            accuracy += accuracy_score(prediction_df.actual, prediction_df.predicted)\n",
    "            recall += recall_score(prediction_df.actual, prediction_df.predicted)\n",
    "            f1 += f1_score(prediction_df.actual, prediction_df.predicted)\n",
    "        \n",
    "        self.ridge_metrics = {'precision': precision/len(x['raceId'].unique()), 'accuracy': accuracy/len(x['raceId'].unique()), 'recall': recall/len(x['raceId'].unique()), 'f1': f1/len(x['raceId'].unique())}\n",
    "        return precision/len(x['raceId'].unique())\n",
    "\n",
    "    def find_best_param_ridge(self, x, y):\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        splitter = customCrossValidation().split(x)\n",
    "        \n",
    "        # hyper_params = [{'alpha': [0.001, 0.01, 0.1, 1, 5, 10, 100, 1000], 'solver': ['svd', 'cholesky', 'saga']}]\n",
    "        hyper_params = [{'alpha': [1000], 'solver': ['svd']}]\n",
    "\n",
    "        model_ridge = Ridge()\n",
    "        model_cv = GridSearchCV(estimator=model_ridge, param_grid=hyper_params, scoring=self.my_scoring, cv = splitter, return_train_score=True, verbose = 3)\n",
    "        model_cv.fit(x, y)\n",
    "        self.ridge_params = model_cv.best_params_\n",
    "\n",
    "    def fit_ridge(self, x, y):\n",
    "        model = Ridge(**self.ridge_params)\n",
    "        model.fit(x, y)\n",
    "        self.model = model\n",
    "        return\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 10. 11. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 12. 14. 15.]\n",
      "[ 1.  4.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 0.  5.  6.  7.  8. 11. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 14. 16.]\n",
      "[ 3.  5.  7.  8.  9. 10. 13. 17.]\n",
      "[ 0.  4.  5.  6.  7.  8. 13. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8.  9. 10. 13. 15. 16. 17.]\n",
      "[ 4.  6.  7.  9. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 13. 16.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 10. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 13. 14.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 1.  4. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 4.  5.  8. 11. 12. 13.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 1. 11. 12. 13.]\n",
      "[ 1.  4.  5. 11. 12. 13.]\n",
      "[ 1.  4. 11. 12. 13.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5.  8. 11. 12. 13. 15.]\n",
      "[ 2. 10. 11. 12. 13.]\n",
      "[ 1.  3.  4. 11. 12.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 5. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 15.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 15. 16. 17. 20.]\n",
      "[ 4.  5.  6.  7.  8. 11. 13. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8.  9. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7.  8.  9. 13. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8. 11. 12. 13. 14. 16.]\n",
      "[ 1.  3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  8. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 10. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 15. 17. 18.]\n",
      "[ 2.  4.  5.  6.  8. 14. 15. 16. 17.]\n",
      "[ 4.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 16.]\n",
      "[ 4.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8. 11. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 14. 16. 17.]\n",
      "[ 3.  4.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 14. 15.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  6.  8.  9. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 6.  7. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[-0.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 13. 14. 15.]\n",
      "[ 4.  5.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 4.  5.  7.  8. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 14. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 10. 12. 13. 16. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 11. 12. 13. 14. 15.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[-0.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  7.  8. 11. 12. 13. 14. 16. 17. 18.]\n",
      "[ 1.  4.  6. 13. 14. 15.]\n",
      "[ 0.  4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 1.  3.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 0.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 13. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 11. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 13. 16. 17. 18.]\n",
      "[ 1.  5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  5.  6.  7. 11. 13. 14. 15.]\n",
      "[ 4.  5.  7.  8. 10. 11. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8. 10. 11. 12. 15. 16. 18. 19.]\n",
      "[ 1.  5.  6.  7.  8.  9. 10. 11. 14. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 11. 14. 15. 16. 17.]\n",
      "[-0.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15.]\n",
      "[ 1.  4.  6. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7.  8.  9. 12. 13. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 0.  4.  5.  7. 12. 13. 14. 15.]\n",
      "[ 1.  4.  6.  7.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 10. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 12. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8.  9. 11. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 0.  3.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  6.  7.  8.  9. 10. 11. 14. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 0.  3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[-1.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 15. 17. 18.]\n",
      "[-0.  4.  5.  6.  7.  8.  9. 10. 16. 17. 18.]\n",
      "[ 0.  3.  4.  6.  7.  8. 13. 14. 16. 17.]\n",
      "[ 0.  2.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5. 12. 13. 14. 15. 17.]\n",
      "[ 4.  5.  6.  7.  9. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 14. 15. 16. 17.]\n",
      "[ 0.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  8. 14. 15. 16. 17. 18.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 2.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 13. 15. 16.]\n",
      "[ 2.  6.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  9. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8.  9. 12. 13. 14. 16. 17. 18.]\n",
      "[ 1.  2.  5.  6.  7.  8. 14. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 12. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 15. 16. 17. 18.]\n",
      "[ 0.  4.  6.  7.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 0.  3.  4.  5.  6.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 1.  2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  4.  5.  6.  7.  9. 16. 17. 18.]\n",
      "[ 0.  4.  6.  7.  8.  9. 11. 13. 15. 16. 17.]\n",
      "[ 3.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 12. 13. 14. 15. 16.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 13. 14. 15. 16.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 13. 14. 15. 16. 18. 19.]\n",
      "[ 2.  4.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 5.  6.  9. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6. 10. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7.  8.  9. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  9. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4. 12. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7. 11. 13. 15. 16.]\n",
      "[ 3.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 2.  4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 4.  5. 10. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 10. 12. 14. 15. 16.]\n",
      "[ 1.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  9. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 18.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 5.  7.  8.  9. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 2.  4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 2.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5. 13. 14. 15. 16. 19.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  9. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 1.  3.  4.  5.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 14. 17.]\n",
      "[ 4.  6.  7.  8.  9. 10. 11. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  2.  4.  6.  7.  9. 13. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8.  9. 10. 13. 16. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 16. 17.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 12. 14. 15. 16.]\n",
      "[ 3.  4.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  3.  4.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 14. 15. 16. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 15. 16. 17.]\n",
      "[ 1.  5.  6. 12. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8.  9. 10. 11. 12. 13. 15.]\n",
      "[ 0.  3.  5.  7. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  7.  8.  9. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  4.  6.  7. 14. 15. 16. 17.]\n",
      "[ 0.  3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 10. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  7.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 10. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  8. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  8. 10. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  8. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  9. 10. 12. 14. 15. 16. 19.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6.  8. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  9. 10. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  9. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  6.  8.  9. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 10. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 11. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  9. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 5.  6.  8. 11. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 11. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6. 12. 13. 14. 15. 18.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 18.]\n",
      "[ 5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17. 19.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 16. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 16. 17. 19.]\n",
      "[ 6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  8. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4. 10. 11. 12. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  7. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 10. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 5.  6.  7. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13. 14. 15.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 2.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 2.  4. 11. 12. 13.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5.  6.  8. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14. 15.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 3.  4.  9. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13.]\n",
      "[ 3.  5.  9. 10. 11. 12. 13.]\n",
      "[ 2.  3. 10. 11. 12. 13. 14.]\n",
      "[ 2.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5.  9. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 3. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 3. 10. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  9. 10. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  6. 11. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13.]\n",
      "[ 3.  4.  5.  6. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4. 12. 13. 14. 15.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 2.  4. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4. 10. 11. 12.]\n",
      "[ 2.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 3. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4. 10. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13.]\n",
      "[ 4. 10. 11. 12. 13.]\n",
      "[ 4.  6. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 2.  3.  4. 11. 12.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14. 15.]\n",
      "[ 2.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 6.  7. 11. 13. 14. 15.]\n",
      "[ 2.  3. 10. 11. 12.]\n",
      "[ 2. 10. 11. 12.]\n",
      "[ 3.  4.  5.  9. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12.]\n",
      "[ 3.  4. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13.]\n",
      "[ 4.  6.  7. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4.  6.  7. 11. 13. 14. 15.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5. 12. 13. 14. 15. 16.]\n",
      "[ 6. 10. 12. 13. 14. 15.]\n",
      "[ 4.  7. 13. 14. 15.]\n",
      "[ 5.  7. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 6.  7. 11. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  6. 12. 13. 14. 15.]\n",
      "[ 5.  8. 12. 13. 14. 15.]\n",
      "[ 4.  6. 12. 13. 14. 15.]\n",
      "[ 3.  6. 11. 13. 14. 15.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 2. 12. 13. 14.]\n",
      "[ 3. 11. 12.]\n",
      "[ 4.  6.  7. 11. 13. 14.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 3.  5.  7. 12. 13. 14.]\n",
      "[ 4.  5.  6. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 4.  6.  7. 13. 14.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 5.  6. 12. 13. 14. 15.]\n",
      "[ 2.  5. 12. 13. 14.]\n",
      "[ 5.  7.  9. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15. 16.]\n",
      "[ 5.  7. 13. 14. 15.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 5.  7. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  6. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 5. 13. 14. 15.]\n",
      "[ 6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 8.  9. 12. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 10. 14. 15. 16.]\n",
      "[ 7.  8.  9. 10. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8. 14. 15. 16.]\n",
      "[ 7.  8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 15. 16.]\n",
      "[ 8.  9. 10. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[CV 1/5] END alpha=1000, solver=svd;, score=(train=0.740, test=0.678) total time=   0.4s\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  8.  9. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7.  8. 11. 12. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  7.  8. 11. 12. 13. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 16. 17. 18.]\n",
      "[ 4.  5.  7.  8. 10. 11. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5. 12. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 15. 16. 17.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 14. 15.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8.  9. 10. 13. 16. 18.]\n",
      "[ 5.  7.  9. 10. 11. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 16. 17.]\n",
      "[ 4.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13.]\n",
      "[ 4.  5. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 12. 13.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 2.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 3. 11. 12. 13.]\n",
      "[ 5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 15. 16. 17. 20.]\n",
      "[ 4.  5.  6.  7.  8. 11. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  4.  5.  6.  8. 11. 12. 13. 14. 16.]\n",
      "[ 2.  3.  5.  6.  7. 11. 13. 14. 16. 17.]\n",
      "[ 3.  5.  6.  8. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 12. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 10. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 15. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8. 11. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 14. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8. 13. 14. 16. 17. 18.]\n",
      "[ 2.  5. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 14. 15.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 14. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 13. 15. 16.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6. 12. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 6.  7.  8. 10. 13. 14. 16. 17.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 0.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 12. 13. 16. 18.]\n",
      "[ 3.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 12. 13. 14. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 10. 11. 13. 15.]\n",
      "[-0.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6. 13. 14. 15. 16.]\n",
      "[ 0.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 1.  3.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 0.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 13. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 13. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7.  8.  9. 10. 11. 12. 15. 16. 18.]\n",
      "[ 1.  5.  6.  7.  8.  9. 10. 11. 14. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 15. 16.]\n",
      "[ 3.  5.  6.  7.  9. 13. 14. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7. 11. 14. 15. 16. 17.]\n",
      "[-0.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 0.  4.  5.  8. 13. 14. 15.]\n",
      "[ 1.  4.  6.  7.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 10. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8.  9. 13. 14. 15. 16.]\n",
      "[ 1.  3.  4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8.  9. 11. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 0.  3.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  6.  7.  8.  9. 11. 14. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 16.]\n",
      "[ 3.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 0.  3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[-1.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 15. 17. 18.]\n",
      "[ 0.  4.  5.  6.  7.  8.  9. 11. 16. 17. 18.]\n",
      "[ 0.  3.  4.  6.  7.  8. 13. 14. 16. 17.]\n",
      "[ 1.  2.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  8. 14. 15. 16. 17. 18.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7. 13. 14. 16. 17.]\n",
      "[ 2.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  6.  8. 13. 14. 15. 16.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 13. 14. 16. 17. 18.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8.  9. 12. 13. 14. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 11. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 15. 16. 17. 18.]\n",
      "[ 0.  4.  6.  7.  9. 12. 13. 14. 15. 16. 17.]\n",
      "[ 0.  3.  4.  6.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 1.  2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  4.  5.  6.  7.  8. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 13. 14. 15. 16.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 13. 14. 15. 16. 19.]\n",
      "[ 3.  4.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 5.  6.  9. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6. 11. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 6.  7.  8. 10. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  9. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 19.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 4.  6. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 15. 16.]\n",
      "[ 2.  3.  4.  5.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 11. 12. 14. 15. 16.]\n",
      "[ 3.  5.  6.  9. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15. 16.]\n",
      "[ 5.  6.  8. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 5.  7.  8. 10. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  6.  7. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 19.]\n",
      "[ 5.  6.  7.  9. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 13. 14. 17.]\n",
      "[ 4.  6.  7.  8.  9. 10. 11. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  2.  4.  5.  6.  7.  8. 13. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 12. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  3.  4.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 0.  5.  6.  7.  8. 11. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6. 12. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 14. 16.]\n",
      "[ 2.  4.  5.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7.  8.  9. 10. 13. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8.  9. 10. 11. 12. 13. 15.]\n",
      "[ 0.  2.  5.  7. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7.  8. 13. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  7.  8.  9. 10. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7.  8.  9. 10. 13. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  9. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 14. 15. 16. 17.]\n",
      "[ 0.  3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 13. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  7.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8.  9. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 11. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 13. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  8. 10. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  8. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 18.]\n",
      "[ 2.  3.  5. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 18. 19. 20.]\n",
      "[ 3.  5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 10. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 13. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  9. 10. 12. 14. 15. 16. 19.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 6.  8. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  7.  8. 13. 15. 16. 17. 18. 19. 20.]\n",
      "[ 5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  9. 10. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  9. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  3.  6.  8.  9. 12. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 10. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 11. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  9. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8.  9. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  7. 11. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7.  9. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6. 12. 13. 14. 15. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 19.]\n",
      "[ 4.  5.  6. 10. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 19.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5. 12. 13. 14. 15. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17. 19.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 16. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17. 19.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  9. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 13. 14.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4. 11. 12. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  7. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 10. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 1.  4. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 4.  5.  8. 11. 12. 13.]\n",
      "[ 2.  4. 11. 12. 13.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 1. 11. 12. 13.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5.  6.  7. 11. 12. 13.]\n",
      "[ 3.  5.  6. 10. 11. 12. 13. 14. 15.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 1.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 3.  4.  9. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13.]\n",
      "[ 1.  4. 11. 12. 13.]\n",
      "[ 3.  5.  9. 10. 11. 12. 13.]\n",
      "[ 2.  3. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6.  9. 11. 12. 13. 14.]\n",
      "[ 5. 10. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 3.  5. 11. 12. 13.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5.  9. 10. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 4.  5.  8. 11. 12. 13. 15.]\n",
      "[ 3. 10. 12. 13. 14.]\n",
      "[ 2. 10. 11. 12. 13.]\n",
      "[ 1.  3.  4. 11. 12.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  9. 10. 11. 12. 13.]\n",
      "[ 4.  5.  9. 10. 11. 12.]\n",
      "[ 3. 10. 11. 12.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  6. 11. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13.]\n",
      "[ 3.  4.  5.  6. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4. 13. 14. 15.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 10. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12. 13. 15.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 2.  4. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 3. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 4. 10. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 4. 10. 11. 12. 13.]\n",
      "[ 4.  6. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 2.  3.  4. 11. 12.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14. 15.]\n",
      "[ 2.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 6.  7. 11. 13. 14. 15.]\n",
      "[ 1.  3. 10. 11. 12.]\n",
      "[ 2. 10. 11. 12.]\n",
      "[ 3.  4.  5.  9. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12.]\n",
      "[ 3.  4. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13.]\n",
      "[ 4.  6.  7. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4.  6.  7. 11. 13. 14. 15.]\n",
      "[ 6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5. 12. 13. 14. 15. 16.]\n",
      "[ 6. 10. 12. 13. 14. 15.]\n",
      "[ 4.  7. 13. 14. 15.]\n",
      "[ 5.  7. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 6.  7. 11. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  6. 12. 13. 14. 15.]\n",
      "[ 5.  8. 12. 13. 14. 15.]\n",
      "[ 4.  6. 12. 13. 14. 15.]\n",
      "[ 3.  6. 11. 13. 14. 15.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 2. 12. 13. 14.]\n",
      "[ 3. 11. 12.]\n",
      "[ 4.  6.  7. 11. 13. 14.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 3.  5.  7. 12. 13. 14.]\n",
      "[ 4.  5.  6. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 4.  6.  7. 13. 14.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 4.  5. 12. 13. 14.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 2.  5. 12. 13. 14.]\n",
      "[ 5.  7.  9. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15. 16.]\n",
      "[ 5.  7. 13. 14. 15.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 5.  7. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  6. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 12. 13. 14.]\n",
      "[ 5. 13. 14. 15.]\n",
      "[ 6.  7.  8. 12. 14. 15.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 4.  7. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 8.  9. 12. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 10. 14. 15. 16.]\n",
      "[ 7.  8.  9. 10. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8. 14. 15. 16.]\n",
      "[ 7.  8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 15. 16.]\n",
      "[ 8.  9. 10. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[CV 2/5] END alpha=1000, solver=svd;, score=(train=0.738, test=0.686) total time=   0.4s\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 0.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 13. 15. 16.]\n",
      "[ 0.  4.  5.  8. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  5.  7. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  7.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 11. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6.  8. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  9. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 11. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 18.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 18.]\n",
      "[ 5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 16. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 18.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17. 18.]\n",
      "[ 4.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13.]\n",
      "[ 4.  5. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 5.  7. 11. 13. 14. 15.]\n",
      "[ 6.  7.  8. 12. 14. 15.]\n",
      "[ 5.  6.  7. 12. 13. 14.]\n",
      "[ 4.  7. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 8. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 15. 16. 17. 20.]\n",
      "[ 4.  5.  6.  7.  8. 11. 13. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8.  9. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 12. 13. 14. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 11. 13. 14. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8.  9. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8. 11. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 5.  7. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 14. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  8. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8.  9. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6.  8.  9. 11. 13. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 6.  7.  8. 10. 12. 13. 14. 16. 17.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 0.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 11. 14. 16.]\n",
      "[ 4.  5.  7.  8.  9. 12. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 16. 18. 19.]\n",
      "[ 3.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 12. 13. 14. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 10. 11. 13. 14. 15. 16.]\n",
      "[ 0.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  7.  8.  9. 11. 12. 13. 14. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 1.  3.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 0.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 13. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 16.]\n",
      "[ 4.  5.  7.  8. 10. 11. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8.  9. 10. 11. 12. 16. 18. 19.]\n",
      "[ 1.  5.  6.  7.  8.  9. 10. 11. 14. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 15. 16.]\n",
      "[ 3.  5.  6.  7.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 14. 15. 16. 17.]\n",
      "[-0.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  6.  7.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 10. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8.  9. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  8.  9. 11. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 0.  3.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  6.  7.  8.  9. 10. 11. 13. 14. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 0.  3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[-1.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 11. 13. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 15. 18. 19.]\n",
      "[ 0.  4.  5.  6.  7.  8.  9. 10. 16. 17. 18.]\n",
      "[ 0.  3.  4.  6.  7.  8. 13. 14. 16. 17.]\n",
      "[ 1.  2.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 16. 17.]\n",
      "[ 3.  5.  6. 12. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  9. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  8. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7. 13. 14. 16. 17.]\n",
      "[ 2.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  9. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8.  9. 10. 12. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 14. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18.]\n",
      "[ 0.  4.  6.  7.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 0.  3.  4.  5.  6.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  4.  5.  6.  7.  8.  9. 16. 17. 18.]\n",
      "[ 1.  4.  6.  7.  9. 11. 13. 15. 16. 17.]\n",
      "[ 3.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 13. 14. 15. 16.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 5.  6.  9. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6. 10. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7.  8.  9. 10. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  9. 12. 13. 14. 15. 16. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 4.  6. 10. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 15. 16.]\n",
      "[ 2.  3.  4.  5.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 10. 12. 14. 15. 16.]\n",
      "[ 1.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  9. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15. 16.]\n",
      "[ 5.  6.  8. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 5.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5. 13. 14. 15. 16. 18. 19.]\n",
      "[ 2.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  9. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 11. 13. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 11. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  8. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 13. 14. 17.]\n",
      "[ 4.  6.  7.  8.  9. 10. 11. 15. 16. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  2.  4.  6.  7.  8.  9. 13. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8.  9. 10. 13. 16. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8.  9. 10. 11. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 13. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 12. 16. 17.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  7.  8.  9. 10. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  9. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8. 11. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 11. 14. 15. 16.]\n",
      "[ 2.  5.  6. 11. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 14. 16.]\n",
      "[ 1.  4.  5.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7.  8.  9. 10. 12. 13. 17.]\n",
      "[ 1.  4.  5.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  7.  8.  9. 10. 11. 12. 13. 15.]\n",
      "[ 1.  3.  5.  7. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7.  8. 13. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8.  9. 10. 12. 13. 14. 15.]\n",
      "[ 1.  4.  6.  7.  8.  9. 10. 13. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  9. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  4.  6.  7. 14. 15. 16. 17.]\n",
      "[ 1.  3.  5.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 13. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 10. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  7. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 13. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 13. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  9. 10. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  6.  8.  9. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 10. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 10. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  9. 13. 14. 15. 16. 17. 18. 20.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  7. 11. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  7. 10. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  9. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 4.  5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 18.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  8. 11. 12. 13. 14. 15. 16. 18.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4. 10. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6.  7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  9. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 13. 14. 15.]\n",
      "[ 3.  4.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 13. 14.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 5.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4. 10. 11. 12. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  7. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 10. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14.]\n",
      "[ 5.  6. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14.]\n",
      "[ 2.  5.  6. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 1.  4. 11. 12. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5.  8. 11. 12. 13.]\n",
      "[ 2.  4. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3. 11. 12. 13.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 1. 11. 12. 13.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5.  6.  8. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 12. 13.]\n",
      "[ 3.  5.  6. 10. 11. 12. 13. 14. 15.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 1.  4.  5. 11. 12. 13.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 4.  9. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13.]\n",
      "[ 1.  4. 11. 12. 13.]\n",
      "[ 3.  5.  9. 10. 11. 12. 13.]\n",
      "[ 2.  3. 10. 11. 12. 13. 14.]\n",
      "[ 2.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5.  6.  9. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 5. 10. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 3.  5. 11. 12. 13.]\n",
      "[ 2.  4.  5. 11. 12. 13.]\n",
      "[ 3. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4.  5.  9. 11. 12. 13.]\n",
      "[ 5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 4.  5.  8. 11. 12. 13. 15.]\n",
      "[ 3. 10. 12. 13. 14.]\n",
      "[ 2. 11. 12. 13.]\n",
      "[ 1.  3.  4. 11. 12.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  9. 10. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 4.  6. 11. 12. 13. 14.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 5.  7. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5.  6. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4. 13. 14. 15.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  9. 10. 11. 12. 13.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14.]\n",
      "[ 5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 2.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13. 14.]\n",
      "[ 2.  4. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12.]\n",
      "[ 2.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 3. 11. 12. 13. 14. 15.]\n",
      "[ 4.  6. 11. 12. 13. 14.]\n",
      "[ 3.  5. 10. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  4. 11. 12. 13. 14.]\n",
      "[ 4. 10. 11. 12. 13.]\n",
      "[ 4.  9. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 4. 10. 11. 12. 13.]\n",
      "[ 4.  6. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 2.  3.  4. 10. 11. 12.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13. 14.]\n",
      "[ 2.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 12. 13. 14.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 6.  7. 11. 13. 14. 15.]\n",
      "[ 2.  3. 10. 11. 12.]\n",
      "[ 2. 10. 11. 12.]\n",
      "[ 3.  4.  5.  9. 10. 11. 12. 13. 14.]\n",
      "[ 3. 10. 11. 12. 13.]\n",
      "[ 3. 10. 11. 12.]\n",
      "[ 3.  4. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 11. 12. 13.]\n",
      "[ 4.  6.  7.  8. 13. 14.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14. 15.]\n",
      "[ 4. 11. 12. 13. 14.]\n",
      "[ 4.  7. 11. 13. 14. 15.]\n",
      "[ 6.  8. 11. 12. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15. 16.]\n",
      "[ 6. 10. 13. 14. 15.]\n",
      "[ 4.  7. 13. 14. 15.]\n",
      "[ 5.  7. 11. 13. 14. 15.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15.]\n",
      "[ 6.  7. 11. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  6. 12. 13. 14. 15.]\n",
      "[ 5.  8. 13. 14. 15.]\n",
      "[ 4.  6. 12. 13. 14. 15.]\n",
      "[ 4.  6. 11. 13. 14. 15.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 2. 12. 13. 14. 15.]\n",
      "[ 3. 11. 12.]\n",
      "[ 4.  6.  7. 11. 13. 14.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 5.  7. 12. 13. 14.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 4.  6.  7. 13. 14.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 6. 12. 13. 14. 15.]\n",
      "[ 2.  5. 12. 13. 14.]\n",
      "[ 5.  7.  9. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14. 15. 16.]\n",
      "[ 5.  7. 13. 14. 15.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14. 15.]\n",
      "[ 5. 12. 13. 14. 15.]\n",
      "[ 5.  6. 12. 13. 14.]\n",
      "[ 5. 12. 13. 14.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  6. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 6. 12. 13. 14.]\n",
      "[ 8.  9. 13. 14. 15. 16.]\n",
      "[ 8.  9. 15. 16.]\n",
      "[ 8.  9. 10. 15. 16.]\n",
      "[ 8.  9. 10. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[ 8.  9. 15. 16.]\n",
      "[ 8.  9. 15. 16.]\n",
      "[ 8.  9. 10. 15. 16.]\n",
      "[ 8.  9. 10. 14. 15. 16.]\n",
      "[ 8.  9. 14. 15. 16.]\n",
      "[CV 3/5] END alpha=1000, solver=svd;, score=(train=0.731, test=0.794) total time=   0.6s\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 16.]\n",
      "[ 2.  5.  6.  7.  9. 13. 14. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 11. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8. 11. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8. 13. 14. 16. 17. 18.]\n",
      "[ 2.  3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 14. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7.  8. 10. 13. 14. 16. 17.]\n",
      "[ 2.  4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  9. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8. 10. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 2.  3.  6.  7.  8.  9. 10. 11. 14. 16. 17.]\n",
      "[ 1.  2.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7.  8. 14. 16. 17. 18.]\n",
      "[ 2.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6. 12. 13. 14. 15. 18.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 19.]\n",
      "[ 5. 12. 13. 14. 15. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17. 19.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15. 16. 19.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6. 13. 14. 15. 16. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17. 19.]\n",
      "[ 4.  6.  7.  9. 10. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4. 10. 11. 12. 13.]\n",
      "[ 5.  8. 13. 14. 15. 16.]\n",
      "[ 5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 11. 12. 13. 15.]\n",
      "[ 5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 3.  5. 10. 11. 12. 13. 14.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 3.  5. 11. 12. 13. 14.]\n",
      "[ 3.  4. 11. 12. 13.]\n",
      "[ 4. 11. 12. 13.]\n",
      "[ 3.  4.  5. 10. 11. 12. 13.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16.]\n",
      "[ 6.  7.  8. 12. 14. 15.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15.]\n",
      "[ 7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 5.  6. 13. 14. 15.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15.]\n",
      "[ 5.  8. 13. 14. 15.]\n",
      "[ 3.  6.  7. 13. 14. 15.]\n",
      "[ 7.  8.  9. 10. 15. 16.]\n",
      "[ 8.  9. 10. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 17.]\n",
      "[ 5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 15. 16. 17. 20. 21.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 11. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8.  9. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 12. 13. 14. 16.]\n",
      "[ 3.  5.  6.  7.  8. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 17. 18.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8.  9. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 13. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 13. 14. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 15.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 13. 15. 16.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6. 12. 13. 14. 16. 17.]\n",
      "[ 2.  4.  5.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 0.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7.  8. 11. 12. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 14. 15. 16.]\n",
      "[ 3.  4.  5.  7.  8.  9. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 12. 13. 16. 18. 19.]\n",
      "[ 3.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 12. 13. 14. 16.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 10. 11. 13. 15. 16.]\n",
      "[ 0.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  7.  8.  9. 11. 12. 13. 14. 16. 17. 18.]\n",
      "[ 1.  4.  6. 13. 14. 15. 16.]\n",
      "[ 0.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 0.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 13. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 11. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5.  6.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15.]\n",
      "[ 4.  5.  7.  8. 10. 11. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8. 10. 11. 12. 16. 18.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 11. 14. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 11. 14. 15. 16. 17.]\n",
      "[-0.  5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 1.  4.  6. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 0.  4.  5.  8. 12. 13. 14. 15.]\n",
      "[ 1.  4.  5.  6.  7.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  8.  9. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8.  9. 11. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 1.  3.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 16.]\n",
      "[ 3.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[-1.  4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 11. 12. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 11. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 15. 17. 18.]\n",
      "[ 0.  4.  5.  6.  7.  8.  9. 11. 16. 17. 18.]\n",
      "[ 0.  3.  4.  6.  7.  8. 13. 14. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 16. 17. 18.]\n",
      "[ 2.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 4. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 1.  5. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7.  9. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 13. 14. 15. 16.]\n",
      "[ 2.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  7. 12. 13. 15. 16.]\n",
      "[ 2.  6.  8. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6.  7.  8. 13. 16. 17. 18.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  8. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  6.  7.  8.  9. 10. 12. 13. 14. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 11. 12. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 13. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18.]\n",
      "[ 1.  4.  6.  7.  9. 12. 14. 15. 16. 17.]\n",
      "[ 0.  3.  5.  6.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 1.  3.  5.  6.  7.  8.  9. 16. 17. 18.]\n",
      "[ 1.  4.  6.  7.  8.  9. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  8. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5. 11. 12. 13. 14. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 14. 15. 16.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8. 11. 12. 14. 15. 16.]\n",
      "[ 5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 13. 14. 15. 16. 19.]\n",
      "[ 2.  4.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 19.]\n",
      "[ 5.  6.  9. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6. 11. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 1.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7.  8. 10. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  9. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  4. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 10. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 19.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  5.  6.  7. 14. 15. 16.]\n",
      "[ 4.  6. 10. 11. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 12. 13. 15. 16.]\n",
      "[ 2.  3.  4.  5.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5.  6.  7. 11. 12. 14. 15. 16.]\n",
      "[ 1.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 10. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 18. 19.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 14. 15. 16. 17.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 11. 13. 14. 15. 16.]\n",
      "[ 5.  6.  8. 11. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  5.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 13. 14. 15. 16. 18. 19.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16.]\n",
      "[ 5.  7.  8. 10. 12. 13. 14. 15. 16. 19.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 2.  3.  5.  6.  7. 14. 15. 16.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  7. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5.  6.  7.  8. 12. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16.]\n",
      "[ 2.  4.  6. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5. 13. 14. 15. 16. 19.]\n",
      "[ 2.  5. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7.  9. 11. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 14. 15.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 2.  3.  4.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  8. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 12. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "[ 2.  4.  6.  7.  8.  9. 10. 13. 14. 17.]\n",
      "[ 4.  6.  7.  8.  9. 10. 11. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  6.  7.  8.  9. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  2.  4.  6.  7.  9. 13. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  8.  9. 10. 13. 16. 18.]\n",
      "[ 3.  5.  6.  7.  8. 13. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7.  8.  9. 10. 11. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 10. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 13. 16. 17.]\n",
      "[ 3.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  4.  6.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  7.  8.  9. 10. 13. 14. 15. 16.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 12. 15. 16.]\n",
      "[ 4.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 10. 14. 15. 16. 17.]\n",
      "[ 4.  6.  9. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7.  8.  9. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8. 11. 14. 15. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 13. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8.  9. 10. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7.  8. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 12. 14. 15. 16.]\n",
      "[ 2.  5.  6. 12. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7.  8. 12. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 14. 16.]\n",
      "[ 2.  4.  5.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7.  8.  9. 10. 13. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 10. 14. 15. 16.]\n",
      "[ 1.  4.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  5.  6.  7.  8.  9. 10. 11. 12. 13. 15.]\n",
      "[ 1.  3.  5.  7. 14. 15. 16. 17.]\n",
      "[ 0.  4.  5.  6.  7.  8. 13. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17. 18.]\n",
      "[ 2.  5.  7.  8.  9. 10. 12. 13. 14. 15.]\n",
      "[ 1.  4.  6.  7.  8.  9. 10. 13. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  9. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8. 13. 14. 15. 16. 17. 18.]\n",
      "[ 1.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  7. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  7.  8.  9. 10. 13. 14. 15. 16. 17.]\n",
      "[ 1.  4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  6.  7.  8.  9. 12. 13. 17.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  7.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 10. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  4.  5.  6.  7.  8.  9. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6.  8.  9. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  8. 11. 12. 13. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  8. 13. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  7. 11. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  6.  8. 10. 12. 13. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 18.]\n",
      "[ 2.  3.  5. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  7.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 10. 13. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  9. 10. 12. 14. 15. 16. 19. 20.]\n",
      "[ 5.  6. 10. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 6.  8. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 12. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  7.  8. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7.  9. 10. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  3.  5.  6. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  9. 10. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  3.  6.  7.  9. 12. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 10. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 6.  7. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 10. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4. 12. 13. 14. 15. 16. 18.]\n",
      "[ 5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  7. 11. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 5.  6.  7.  9. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  6.  8. 11. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4.  5.  6.  9. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  4.  6. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 3.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  5.  6.  7. 12. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  8. 12. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      "[ 2.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 11. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  6.  7. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 11. 13. 14. 15. 16. 17.]\n",
      "[ 6. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  7. 11. 13. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  8. 10. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  7. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  5.  7.  8.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 2.  3.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7.  9. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8. 12. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  5.  6.  7.  8. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6.  7.  8.  9. 12. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6.  7.  8. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  9. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 2.  4.  5.  6.  7.  9. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  4.  5.  7.  8. 12. 13. 14. 15. 16. 18.]\n",
      "[ 3.  4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  6. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
      "[ 4.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 5.  6. 11. 12. 13. 14. 15. 16. 17. 19.]\n",
      "[ 5.  7. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 4.  6.  7. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  8. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4. 10. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7.  8. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15. 16.]\n",
      "[ 5.  6.  7. 11. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  7. 12. 13. 14. 15. 16.]\n",
      "[ 3.  6.  7.  8. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  9. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  6. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 13. 14. 15. 16.]\n",
      "[ 3.  4.  6. 11. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 12. 13. 14.]\n",
      "[ 3.  4.  5.  6.  7.  8. 13. 14. 15.]\n",
      "[ 5.  6.  7. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 3.  5.  6.  7. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  7. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 5.  8. 10. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4. 10. 11. 12. 13. 14. 15. 17.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  7. 12. 13. 14.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6.  8. 10. 11. 12. 13. 14. 15.]\n",
      "[ 3.  5.  6. 12. 13. 14. 15.]\n",
      "[ 4.  5. 10. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15. 16.]\n",
      "[ 3.  4.  5. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5. 11. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  8. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6. 12. 13. 14. 15. 16. 17.]\n",
      "[ 4.  5.  6.  7. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 11. 12. 13. 14.]\n",
      "[ 4.  5. 11. 12. 13. 14.]\n",
      "[ 3.  5. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5.  6.  7. 11. 12. 13. 14. 15.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6. 10. 11. 12. 13. 14. 15.]\n",
      "[ 3.  4.  5. 11. 12. 13. 14. 15. 16.]\n",
      "[ 4.  5.  6. 11. 12. 13. 14. 15.]\n",
      "[ 5.  6.  7. 10. 11. 12. 13. 14.]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# print(df_train)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lr\u001b[39m.\u001b[39;49mfind_best_param_ridge(df_train\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mresults_positionOrder\u001b[39;49m\u001b[39m'\u001b[39;49m], axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m), df_train[\u001b[39m'\u001b[39;49m\u001b[39mresults_positionOrder\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn [35], line 42\u001b[0m, in \u001b[0;36mlinearRegression.find_best_param_ridge\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     40\u001b[0m model_ridge \u001b[39m=\u001b[39m Ridge()\n\u001b[0;32m     41\u001b[0m model_cv \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel_ridge, param_grid\u001b[39m=\u001b[39mhyper_params, scoring\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmy_scoring, cv \u001b[39m=\u001b[39m splitter, return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m model_cv\u001b[39m.\u001b[39;49mfit(x, y)\n\u001b[0;32m     43\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mridge_params \u001b[39m=\u001b[39m model_cv\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:711\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m     score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m     \u001b[39mif\u001b[39;00m return_train_score:\n\u001b[1;32m--> 711\u001b[0m         train_scores \u001b[39m=\u001b[39m _score(estimator, X_train, y_train, scorer, error_score)\n\u001b[0;32m    713\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    714\u001b[0m     total_time \u001b[39m=\u001b[39m score_time \u001b[39m+\u001b[39m fit_time\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m error_score \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "Cell \u001b[1;32mIn [35], line 10\u001b[0m, in \u001b[0;36mlinearRegression.my_scoring\u001b[1;34m(self, model, x, y)\u001b[0m\n\u001b[0;32m      8\u001b[0m f1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m x[\u001b[39m'\u001b[39m\u001b[39mraceId\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique():\n\u001b[1;32m---> 10\u001b[0m     prediction_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(model\u001b[39m.\u001b[39mpredict(x[x[\u001b[39m'\u001b[39;49m\u001b[39mraceId\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m i]), columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mround(prediction_df[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues)))\n\u001b[0;32m     12\u001b[0m     Y_test \u001b[39m=\u001b[39m y[x[x[\u001b[39m'\u001b[39m\u001b[39mraceId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m i]\u001b[39m.\u001b[39mindex]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5620\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   5622\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 5623\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   5625\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:286\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    283\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    285\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    288\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    160\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    166\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     68\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(df_train)\n",
    "lr.find_best_param_ridge(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1000, 'solver': 'svd'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.ridge_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit_ridge(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6006289308176098"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.my_scoring(lr.model, df_test.drop(['results_positionOrder'], axis = 1), df_test['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>0.600629</td>\n",
       "      <td>0.89656</td>\n",
       "      <td>0.600629</td>\n",
       "      <td>0.600629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision  accuracy    recall        f1\n",
       "ridge   0.600629   0.89656  0.600629  0.600629"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr.ridge_metrics, index = ['ridge'], columns = ['precision', 'accuracy', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lassoRegression():\n",
    "    def my_scoring(self, model, x, y):\n",
    "\n",
    "        precision = 0\n",
    "        accuracy = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "        for i in x['raceId'].unique():\n",
    "            prediction_df = pd.DataFrame(model.predict(x[x['raceId'] == i]), columns = ['results'])\n",
    "            Y_test = y[x[x['raceId'] == i].index]\n",
    "\n",
    "            \n",
    "            prediction_df['podium'] = Y_test.reset_index(drop = True)\n",
    "            prediction_df['actual'] = prediction_df.podium.map(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "            prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "            prediction_df.reset_index(inplace = True, drop = True)\n",
    "            prediction_df['predicted'] = prediction_df.index\n",
    "            prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "            precision += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "            accuracy += accuracy_score(prediction_df.actual, prediction_df.predicted)\n",
    "            recall += recall_score(prediction_df.actual, prediction_df.predicted)\n",
    "            f1 += f1_score(prediction_df.actual, prediction_df.predicted)\n",
    "        \n",
    "        self.ridge_metrics = {'precision': precision/len(x['raceId'].unique()), 'accuracy': accuracy/len(x['raceId'].unique()), 'recall': recall/len(x['raceId'].unique()), 'f1': f1/len(x['raceId'].unique())}\n",
    "        return precision/len(x['raceId'].unique())\n",
    "\n",
    "    def find_best_param_lasso(self, x, y):\n",
    "\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "        splitter = customCrossValidation().split(x)\n",
    "        \n",
    "        hyper_params = [{'alpha': [0.1, 1, 5, 10, 100, 1000, 2000], 'selection': ['cyclic', 'random']}]\n",
    "\n",
    "        model_lasso = Lasso()\n",
    "        model_cv = GridSearchCV(estimator=model_lasso, param_grid=hyper_params, scoring=self.my_scoring, cv = splitter, return_train_score=True, verbose = 3)\n",
    "        model_cv.fit(x, y)\n",
    "        self.lasso_params = model_cv.best_params_\n",
    "\n",
    "    def fit_lasso(self, x, y):\n",
    "        model = Lasso(**self.lasso_params)\n",
    "        model.fit(x, y)\n",
    "        self.model = model\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = lassoRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END alpha=0.1, selection=cyclic;, score=(train=0.822, test=0.973) total time=   0.5s\n",
      "[CV 2/5] END alpha=0.1, selection=cyclic;, score=(train=0.841, test=0.857) total time=   0.5s\n",
      "[CV 3/5] END alpha=0.1, selection=cyclic;, score=(train=0.833, test=0.903) total time=   0.4s\n",
      "[CV 4/5] END alpha=0.1, selection=cyclic;, score=(train=0.831, test=0.852) total time=   0.5s\n",
      "[CV 5/5] END alpha=0.1, selection=cyclic;, score=(train=0.843, test=0.797) total time=   0.5s\n",
      "[CV 1/5] END alpha=0.1, selection=random;, score=(train=0.822, test=0.973) total time=   0.4s\n",
      "[CV 2/5] END alpha=0.1, selection=random;, score=(train=0.841, test=0.857) total time=   0.4s\n",
      "[CV 3/5] END alpha=0.1, selection=random;, score=(train=0.833, test=0.903) total time=   0.3s\n",
      "[CV 4/5] END alpha=0.1, selection=random;, score=(train=0.831, test=0.852) total time=   0.4s\n",
      "[CV 5/5] END alpha=0.1, selection=random;, score=(train=0.843, test=0.797) total time=   0.6s\n",
      "[CV 1/5] END alpha=1, selection=cyclic;, score=(train=0.853, test=0.973) total time=   0.3s\n",
      "[CV 2/5] END alpha=1, selection=cyclic;, score=(train=0.875, test=0.896) total time=   0.3s\n",
      "[CV 3/5] END alpha=1, selection=cyclic;, score=(train=0.876, test=0.919) total time=   0.3s\n",
      "[CV 4/5] END alpha=1, selection=cyclic;, score=(train=0.874, test=0.864) total time=   0.4s\n",
      "[CV 5/5] END alpha=1, selection=cyclic;, score=(train=0.879, test=0.823) total time=   0.4s\n",
      "[CV 1/5] END alpha=1, selection=random;, score=(train=0.853, test=0.973) total time=   0.3s\n",
      "[CV 2/5] END alpha=1, selection=random;, score=(train=0.875, test=0.896) total time=   0.4s\n",
      "[CV 3/5] END alpha=1, selection=random;, score=(train=0.876, test=0.919) total time=   0.3s\n",
      "[CV 4/5] END alpha=1, selection=random;, score=(train=0.874, test=0.864) total time=   0.4s\n",
      "[CV 5/5] END alpha=1, selection=random;, score=(train=0.879, test=0.823) total time=   0.4s\n",
      "[CV 1/5] END alpha=5, selection=cyclic;, score=(train=0.655, test=0.521) total time=   0.3s\n",
      "[CV 2/5] END alpha=5, selection=cyclic;, score=(train=0.651, test=0.571) total time=   0.3s\n",
      "[CV 3/5] END alpha=5, selection=cyclic;, score=(train=0.647, test=0.565) total time=   0.2s\n",
      "[CV 4/5] END alpha=5, selection=cyclic;, score=(train=0.644, test=0.630) total time=   0.3s\n",
      "[CV 5/5] END alpha=5, selection=cyclic;, score=(train=0.645, test=0.633) total time=   0.3s\n",
      "[CV 1/5] END alpha=5, selection=random;, score=(train=0.655, test=0.521) total time=   0.3s\n",
      "[CV 2/5] END alpha=5, selection=random;, score=(train=0.651, test=0.571) total time=   0.4s\n",
      "[CV 3/5] END alpha=5, selection=random;, score=(train=0.647, test=0.565) total time=   0.2s\n",
      "[CV 4/5] END alpha=5, selection=random;, score=(train=0.644, test=0.630) total time=   0.3s\n",
      "[CV 5/5] END alpha=5, selection=random;, score=(train=0.645, test=0.633) total time=   0.3s\n",
      "[CV 1/5] END alpha=10, selection=cyclic;, score=(train=0.559, test=0.411) total time=   0.3s\n",
      "[CV 2/5] END alpha=10, selection=cyclic;, score=(train=0.649, test=0.571) total time=   0.3s\n",
      "[CV 3/5] END alpha=10, selection=cyclic;, score=(train=0.559, test=0.387) total time=   0.2s\n",
      "[CV 4/5] END alpha=10, selection=cyclic;, score=(train=0.647, test=0.630) total time=   0.3s\n",
      "[CV 5/5] END alpha=10, selection=cyclic;, score=(train=0.647, test=0.620) total time=   0.3s\n",
      "[CV 1/5] END alpha=10, selection=random;, score=(train=0.559, test=0.411) total time=   0.3s\n",
      "[CV 2/5] END alpha=10, selection=random;, score=(train=0.649, test=0.571) total time=   0.3s\n",
      "[CV 3/5] END alpha=10, selection=random;, score=(train=0.559, test=0.387) total time=   0.2s\n",
      "[CV 4/5] END alpha=10, selection=random;, score=(train=0.647, test=0.630) total time=   0.3s\n",
      "[CV 5/5] END alpha=10, selection=random;, score=(train=0.647, test=0.620) total time=   0.3s\n",
      "[CV 1/5] END alpha=100, selection=cyclic;, score=(train=0.184, test=0.178) total time=   0.4s\n",
      "[CV 2/5] END alpha=100, selection=cyclic;, score=(train=0.178, test=0.247) total time=   0.4s\n",
      "[CV 3/5] END alpha=100, selection=cyclic;, score=(train=0.190, test=0.097) total time=   0.3s\n",
      "[CV 4/5] END alpha=100, selection=cyclic;, score=(train=0.193, test=0.086) total time=   0.4s\n",
      "[CV 5/5] END alpha=100, selection=cyclic;, score=(train=0.193, test=0.076) total time=   0.3s\n",
      "[CV 1/5] END alpha=100, selection=random;, score=(train=0.184, test=0.178) total time=   0.3s\n",
      "[CV 2/5] END alpha=100, selection=random;, score=(train=0.178, test=0.247) total time=   0.3s\n",
      "[CV 3/5] END alpha=100, selection=random;, score=(train=0.190, test=0.097) total time=   0.2s\n",
      "[CV 4/5] END alpha=100, selection=random;, score=(train=0.193, test=0.086) total time=   0.3s\n",
      "[CV 5/5] END alpha=100, selection=random;, score=(train=0.193, test=0.076) total time=   0.3s\n",
      "[CV 1/5] END alpha=1000, selection=cyclic;, score=(train=0.184, test=0.178) total time=   0.3s\n",
      "[CV 2/5] END alpha=1000, selection=cyclic;, score=(train=0.178, test=0.247) total time=   0.3s\n",
      "[CV 3/5] END alpha=1000, selection=cyclic;, score=(train=0.190, test=0.097) total time=   0.2s\n",
      "[CV 4/5] END alpha=1000, selection=cyclic;, score=(train=0.193, test=0.086) total time=   0.4s\n",
      "[CV 5/5] END alpha=1000, selection=cyclic;, score=(train=0.193, test=0.076) total time=   0.4s\n",
      "[CV 1/5] END alpha=1000, selection=random;, score=(train=0.184, test=0.178) total time=   0.3s\n",
      "[CV 2/5] END alpha=1000, selection=random;, score=(train=0.178, test=0.247) total time=   0.4s\n",
      "[CV 3/5] END alpha=1000, selection=random;, score=(train=0.190, test=0.097) total time=   0.2s\n",
      "[CV 4/5] END alpha=1000, selection=random;, score=(train=0.193, test=0.086) total time=   0.3s\n",
      "[CV 5/5] END alpha=1000, selection=random;, score=(train=0.193, test=0.076) total time=   0.3s\n",
      "[CV 1/5] END alpha=2000, selection=cyclic;, score=(train=0.184, test=0.178) total time=   0.3s\n",
      "[CV 2/5] END alpha=2000, selection=cyclic;, score=(train=0.178, test=0.247) total time=   0.3s\n",
      "[CV 3/5] END alpha=2000, selection=cyclic;, score=(train=0.190, test=0.097) total time=   0.2s\n",
      "[CV 4/5] END alpha=2000, selection=cyclic;, score=(train=0.193, test=0.086) total time=   0.3s\n",
      "[CV 5/5] END alpha=2000, selection=cyclic;, score=(train=0.193, test=0.076) total time=   0.3s\n",
      "[CV 1/5] END alpha=2000, selection=random;, score=(train=0.184, test=0.178) total time=   0.3s\n",
      "[CV 2/5] END alpha=2000, selection=random;, score=(train=0.178, test=0.247) total time=   0.3s\n",
      "[CV 3/5] END alpha=2000, selection=random;, score=(train=0.190, test=0.097) total time=   0.2s\n",
      "[CV 4/5] END alpha=2000, selection=random;, score=(train=0.193, test=0.086) total time=   0.3s\n",
      "[CV 5/5] END alpha=2000, selection=random;, score=(train=0.193, test=0.076) total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "lasso.find_best_param_lasso(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'selection': 'cyclic'}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.lasso_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit_lasso(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6981132075471698"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.my_scoring(lasso.model, df_test.drop(['results_positionOrder'], axis = 1), df_test['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.88822</td>\n",
       "      <td>0.232704</td>\n",
       "      <td>0.349057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision  accuracy    recall        f1\n",
       "lasso   0.698113   0.88822  0.232704  0.349057"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lasso.ridge_metrics, index = ['lasso'], columns = ['precision', 'accuracy', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecisionTreeRegressor():\n",
    "    def my_scoring(self, model, x, y):\n",
    "\n",
    "        precision = 0\n",
    "        accuracy = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "        for i in x['raceId'].unique():\n",
    "            prediction_df = pd.DataFrame(model.predict(x[x['raceId'] == i]), columns = ['results'])\n",
    "            Y_test = y[x[x['raceId'] == i].index]\n",
    "\n",
    "            \n",
    "            prediction_df['podium'] = Y_test.reset_index(drop = True)\n",
    "            prediction_df['actual'] = prediction_df.podium.map(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "            prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "            prediction_df.reset_index(inplace = True, drop = True)\n",
    "            prediction_df['predicted'] = prediction_df.index\n",
    "            prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "            precision += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "            accuracy += accuracy_score(prediction_df.actual, prediction_df.predicted)\n",
    "            recall += recall_score(prediction_df.actual, prediction_df.predicted)\n",
    "            f1 += f1_score(prediction_df.actual, prediction_df.predicted)\n",
    "        \n",
    "        self.dt_metrics = {'precision': precision/len(x['raceId'].unique()), 'accuracy': accuracy/len(x['raceId'].unique()), 'recall': recall/len(x['raceId'].unique()), 'f1': f1/len(x['raceId'].unique())}\n",
    "        return precision/len(x['raceId'].unique())\n",
    "\n",
    "    def find_best_param_dt(self, x, y):\n",
    "            \n",
    "            self.x = x\n",
    "            self.y = y\n",
    "    \n",
    "            splitter = customCrossValidation().split(x)\n",
    "            \n",
    "            hyper_params = [{'criterion': [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"], 'splitter': ['best', 'random'], 'max_depth': [4, 5, 6, 7, 8, 9, 10], 'max_features': ['sqrt', 'log2']}]\n",
    "    \n",
    "            model_dt = DecisionTreeRegressor()\n",
    "            model_cv = GridSearchCV(estimator=model_dt, param_grid=hyper_params, scoring=self.my_scoring, cv = splitter, return_train_score=True, verbose = 3)\n",
    "            model_cv.fit(x, y)\n",
    "            self.dt_params = model_cv.best_params_\n",
    "    \n",
    "    def fit_dt(self, x, y):\n",
    "        model = DecisionTreeRegressor(**self.dt_params)\n",
    "        model.fit(x, y)\n",
    "        self.model = model\n",
    "        return\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_regressor = CustomDecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.876, test=0.769) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.913, test=0.810) total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.905, test=0.918) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.740, test=0.809) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.877, test=0.828) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.674, test=0.571) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.494, test=0.524) total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.794, test=0.763) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.782, test=0.777) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.842, test=0.742) total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.680, test=0.648) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.817, test=0.743) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.843, test=0.856) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.859, test=0.862) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.673, test=0.742) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.834, test=0.824) total time=   0.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.721, test=0.590) total time=   0.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.391, test=0.175) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.743, test=0.713) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.814, test=0.828) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.908, test=0.912) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.811, test=0.686) total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.884, test=0.887) total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.882, test=0.915) total time=   0.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.811, test=0.839) total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.828, test=0.791) total time=   0.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.659, test=0.429) total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.668, test=0.536) total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.849, test=0.798) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.715, test=0.763) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.889, test=0.824) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.788, test=0.552) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.736, test=0.588) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.851, test=0.894) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.599, test=0.516) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.816, test=0.747) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.824, test=0.695) total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.787, test=0.794) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.707, test=0.723) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.679, test=0.753) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.903, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.908, test=0.752) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.837, test=0.825) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.916, test=0.926) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.891, test=0.914) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.842, test=0.780) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.852, test=0.714) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.889, test=0.814) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.780, test=0.830) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.817, test=0.753) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.896, test=0.868) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.922, test=0.829) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.805, test=0.732) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.868, test=0.904) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.918, test=0.935) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.900, test=0.846) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.776, test=0.705) total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.865, test=0.773) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.638, test=0.564) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.803, test=0.774) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.931, test=0.912) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.902, test=0.695) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.917, test=0.907) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.920, test=0.926) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.899, test=0.903) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.848, test=0.791) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.881, test=0.781) total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.894, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.803, test=0.830) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.741, test=0.699) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.922, test=0.868) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.906, test=0.771) total time=   0.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.927, test=0.887) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.925, test=0.915) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.862, test=0.774) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.897, test=0.846) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.894, test=0.762) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.782, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.802, test=0.819) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.850, test=0.839) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.934, test=0.956) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.899, test=0.648) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.931, test=0.897) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.891, test=0.840) total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.940, test=0.946) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.837, test=0.835) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.923, test=0.819) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.877, test=0.866) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.886, test=0.872) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.821, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.889, test=0.780) total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.923, test=0.781) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.918, test=0.897) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.931, test=0.883) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.912, test=0.957) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.873, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.882, test=0.762) total time=   0.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.800, test=0.722) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.839, test=0.840) total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.783, test=0.710) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.944, test=0.901) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.945, test=0.838) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.939, test=0.907) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.930, test=0.894) total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.903) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.895, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.867, test=0.800) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.910, test=0.876) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.924, test=0.872) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.769, test=0.753) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.936, test=0.868) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.879, test=0.857) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.926, test=0.918) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.939, test=0.883) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.940, test=0.903) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.903, test=0.824) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.873, test=0.781) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.796, test=0.711) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.767, test=0.755) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.899, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.953, test=0.901) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.934, test=0.686) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.916, test=0.835) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.957, test=0.894) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.943, test=0.892) total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.929, test=0.846) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.932, test=0.800) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.873, test=0.794) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.918, test=0.883) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.913, test=0.860) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.950, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.953, test=0.800) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.960, test=0.887) total time=   0.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.949, test=0.840) total time=   0.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.945, test=0.914) total time=   0.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.926, test=0.879) total time=   0.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.887, test=0.724) total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.911, test=0.887) total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.920, test=0.851) total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.732, test=0.774) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.829, test=0.703) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.827, test=0.743) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.588, test=0.443) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.793, test=0.798) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.811, test=0.774) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.680, test=0.582) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.839, test=0.600) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.776, test=0.753) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.677, test=0.628) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.627, test=0.581) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=best;, score=(train=0.775, test=0.659) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=best;, score=(train=0.816, test=0.705) total time=   0.6s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=best;, score=(train=0.826, test=0.742) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=best;, score=(train=0.789, test=0.766) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=best;, score=(train=0.860, test=0.839) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=random;, score=(train=0.678, test=0.626) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=random;, score=(train=0.758, test=0.619) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=random;, score=(train=0.700, test=0.608) total time=   0.9s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=random;, score=(train=0.792, test=0.755) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=4, max_features=log2, splitter=random;, score=(train=0.796, test=0.785) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.802, test=0.758) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.914, test=0.867) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.890, test=0.856) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.891, test=0.915) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.815, test=0.785) total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.738, test=0.703) total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.715, test=0.552) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.818, test=0.763) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.749, test=0.691) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.835, test=0.806) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=best;, score=(train=0.889, test=0.835) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=best;, score=(train=0.818, test=0.705) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=best;, score=(train=0.840, test=0.804) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=best;, score=(train=0.818, test=0.766) total time=   0.5s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=best;, score=(train=0.868, test=0.817) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=random;, score=(train=0.717, test=0.692) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=random;, score=(train=0.769, test=0.610) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=random;, score=(train=0.609, test=0.412) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=random;, score=(train=0.845, test=0.830) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=5, max_features=log2, splitter=random;, score=(train=0.621, test=0.742) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.908, test=0.879) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.825, test=0.648) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.897, test=0.835) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.516, test=0.447) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.856, test=0.849) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.871, test=0.802) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.669, test=0.505) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.679, test=0.577) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.398, test=0.372) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.812, test=0.785) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=best;, score=(train=0.895, test=0.835) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=best;, score=(train=0.910, test=0.810) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=best;, score=(train=0.875, test=0.856) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=best;, score=(train=0.755, test=0.702) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=best;, score=(train=0.877, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=random;, score=(train=0.856, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=random;, score=(train=0.886, test=0.800) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=random;, score=(train=0.840, test=0.825) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=random;, score=(train=0.826, test=0.809) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=6, max_features=log2, splitter=random;, score=(train=0.832, test=0.817) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.898, test=0.879) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.914, test=0.714) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.922, test=0.866) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.898, test=0.904) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.871, test=0.860) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.895, test=0.802) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.857, test=0.657) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.822, test=0.814) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.872, test=0.787) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.827, test=0.849) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=best;, score=(train=0.901, test=0.890) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=best;, score=(train=0.885, test=0.762) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=best;, score=(train=0.919, test=0.897) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=best;, score=(train=0.908, test=0.926) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=best;, score=(train=0.776, test=0.774) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=random;, score=(train=0.871, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=random;, score=(train=0.806, test=0.705) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=random;, score=(train=0.843, test=0.825) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=random;, score=(train=0.875, test=0.915) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=7, max_features=log2, splitter=random;, score=(train=0.822, test=0.839) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.921, test=0.824) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.884, test=0.762) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.919, test=0.876) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.897, test=0.851) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.892) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.842, test=0.769) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.828, test=0.705) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.817, test=0.784) total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.905, test=0.904) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.909, test=0.925) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=best;, score=(train=0.919, test=0.923) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=best;, score=(train=0.942, test=0.800) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=best;, score=(train=0.911, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=best;, score=(train=0.924, test=0.862) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=best;, score=(train=0.909, test=0.903) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=random;, score=(train=0.848, test=0.802) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=random;, score=(train=0.882, test=0.714) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=random;, score=(train=0.800, test=0.732) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=random;, score=(train=0.815, test=0.702) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=8, max_features=log2, splitter=random;, score=(train=0.862, test=0.871) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.931, test=0.802) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.944, test=0.819) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.889, test=0.876) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.939, test=0.883) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.941, test=0.882) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.893, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.910, test=0.819) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.908, test=0.887) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.909, test=0.862) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.889, test=0.817) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=best;, score=(train=0.922, test=0.846) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=best;, score=(train=0.928, test=0.819) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=best;, score=(train=0.937, test=0.897) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=best;, score=(train=0.938, test=0.862) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=best;, score=(train=0.914, test=0.946) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=random;, score=(train=0.899, test=0.824) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=random;, score=(train=0.868, test=0.657) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=random;, score=(train=0.781, test=0.711) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=random;, score=(train=0.885, test=0.809) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=9, max_features=log2, splitter=random;, score=(train=0.907, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.954, test=0.879) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.945, test=0.781) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.927, test=0.814) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.932, test=0.840) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.940, test=0.806) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.932, test=0.890) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.894, test=0.571) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.892, test=0.876) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.922, test=0.830) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.923, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=best;, score=(train=0.954, test=0.901) total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=best;, score=(train=0.945, test=0.790) total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=best;, score=(train=0.950, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=best;, score=(train=0.929, test=0.936) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=best;, score=(train=0.962, test=0.925) total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=random;, score=(train=0.937, test=0.802) total time=   0.3s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=random;, score=(train=0.884, test=0.743) total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=random;, score=(train=0.947, test=0.825) total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=random;, score=(train=0.940, test=0.872) total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, max_features=log2, splitter=random;, score=(train=0.907, test=0.839) total time=   0.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.872, test=0.813) total time=   3.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.886, test=0.790) total time=   3.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.772, test=0.660) total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.822, test=0.830) total time=   4.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.847, test=0.892) total time=   3.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.865, test=0.835) total time=   2.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.509, test=0.524) total time=   2.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.489, test=0.155) total time=   3.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.626, test=0.564) total time=   2.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.710, test=0.742) total time=   2.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.833, test=0.725) total time=   3.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.697, test=0.533) total time=   3.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.878, test=0.866) total time=   3.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.889, test=0.926) total time=   3.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=best;, score=(train=0.792, test=0.753) total time=   3.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.756, test=0.604) total time=   2.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.710, test=0.610) total time=   2.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.802, test=0.784) total time=   2.4s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.634, test=0.574) total time=   2.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=4, max_features=log2, splitter=random;, score=(train=0.742, test=0.753) total time=   2.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.793, test=0.725) total time=   3.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.843, test=0.762) total time=   3.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.908, test=0.897) total time=   3.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.883, test=0.819) total time=   3.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.883, test=0.914) total time=   3.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.347, test=0.297) total time=   3.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.520, test=0.390) total time=   2.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.708, test=0.608) total time=   2.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.878, test=0.904) total time=   2.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.721, test=0.774) total time=   2.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.827, test=0.747) total time=   3.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.863, test=0.686) total time=   3.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.867, test=0.814) total time=   2.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.882, test=0.915) total time=   3.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=best;, score=(train=0.776, test=0.849) total time=   4.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.718, test=0.703) total time=   2.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.842, test=0.705) total time=   2.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.839, test=0.825) total time=   3.3s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.800, test=0.766) total time=   2.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=5, max_features=log2, splitter=random;, score=(train=0.774, test=0.796) total time=   2.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.882, test=0.824) total time=   3.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.916, test=0.829) total time=   3.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.858, test=0.835) total time=   3.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.902, test=0.904) total time=   3.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.901, test=0.882) total time=   4.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.739, test=0.714) total time=   4.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.694, test=0.495) total time=   2.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.825, test=0.814) total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.815, test=0.766) total time=   2.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.667, test=0.634) total time=   2.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.892, test=0.857) total time=   3.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.882, test=0.762) total time=   3.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.777, test=0.753) total time=   3.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.906, test=0.926) total time=   4.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=best;, score=(train=0.884, test=0.892) total time=   3.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.922, test=0.835) total time=   2.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.836, test=0.638) total time=   2.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.809, test=0.773) total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.686, test=0.638) total time=   3.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=6, max_features=log2, splitter=random;, score=(train=0.850, test=0.796) total time=   2.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.899, test=0.846) total time=   3.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.887, test=0.848) total time=   4.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.877, test=0.835) total time=   3.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.899, test=0.840) total time=   3.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.890, test=0.839) total time=   3.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.904, test=0.879) total time=   2.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.843, test=0.714) total time=   2.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.895, test=0.866) total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.849, test=0.862) total time=   3.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.847, test=0.860) total time=   3.0s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.889, test=0.802) total time=   3.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.917, test=0.867) total time=   4.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.864, test=0.794) total time=   3.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.878, test=0.883) total time=   3.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=best;, score=(train=0.909, test=0.903) total time=   3.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.803, test=0.703) total time=   3.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.882, test=0.743) total time=   2.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.744, test=0.649) total time=   3.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.869, test=0.872) total time=   2.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=7, max_features=log2, splitter=random;, score=(train=0.878, test=0.892) total time=   2.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.903, test=0.890) total time=   3.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.893, test=0.752) total time=   3.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.920, test=0.876) total time=   3.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.905, test=0.904) total time=   4.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.910, test=0.892) total time=   3.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.888, test=0.846) total time=   2.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.851, test=0.657) total time=   2.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.811, test=0.804) total time=   3.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.863, test=0.872) total time=   4.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.862, test=0.860) total time=   5.0s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.899, test=0.769) total time=   3.4s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.898, test=0.810) total time=   3.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.910, test=0.866) total time=   3.4s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.885, test=0.851) total time=   3.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=best;, score=(train=0.900, test=0.925) total time=   4.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.794, test=0.769) total time=   2.6s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.872, test=0.724) total time=   2.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.845, test=0.691) total time=   3.0s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.749, test=0.691) total time=   3.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=8, max_features=log2, splitter=random;, score=(train=0.866, test=0.839) total time=   2.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.923, test=0.868) total time=   3.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.906, test=0.743) total time=   3.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.879, test=0.825) total time=   4.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.880, test=0.872) total time=   3.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.909, test=0.882) total time=   3.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.873, test=0.791) total time=   2.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.901, test=0.781) total time=   3.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.886, test=0.794) total time=   3.0s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.887, test=0.915) total time=   2.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.852, test=0.860) total time=   2.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.899, test=0.857) total time=   4.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.917, test=0.857) total time=   4.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.919, test=0.835) total time=   3.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.922, test=0.926) total time=   3.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=best;, score=(train=0.904, test=0.914) total time=   3.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.892, test=0.846) total time=   2.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.899, test=0.790) total time=   3.0s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.851, test=0.825) total time=   2.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.895, test=0.851) total time=   2.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=9, max_features=log2, splitter=random;, score=(train=0.809, test=0.753) total time=   2.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.923, test=0.879) total time=   4.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.937, test=0.838) total time=   3.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.918, test=0.845) total time=   3.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.914, test=0.883) total time=   4.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.917, test=0.925) total time=   3.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.913, test=0.802) total time=   2.6s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.920, test=0.781) total time=   2.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.910, test=0.866) total time=   2.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.856, test=0.809) total time=   2.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.894, test=0.860) total time=   3.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.896, test=0.802) total time=   3.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.936, test=0.867) total time=   3.8s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.910, test=0.845) total time=   4.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.913, test=0.915) total time=   4.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=best;, score=(train=0.937, test=0.903) total time=   4.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.918, test=0.835) total time=   2.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.880, test=0.771) total time=   2.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.879, test=0.804) total time=   2.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.898, test=0.894) total time=   2.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=log2, splitter=random;, score=(train=0.873, test=0.806) total time=   3.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.876, test=0.835) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.696, test=0.552) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.873, test=0.887) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.809, test=0.702) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=best;, score=(train=0.651, test=0.688) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.828, test=0.725) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.737, test=0.505) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.715, test=0.629) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.646, test=0.660) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=4, max_features=sqrt, splitter=random;, score=(train=0.839, test=0.817) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=best;, score=(train=0.927, test=0.901) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=best;, score=(train=0.818, test=0.695) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=best;, score=(train=0.872, test=0.866) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=best;, score=(train=0.753, test=0.777) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=best;, score=(train=0.842, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=random;, score=(train=0.851, test=0.857) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=random;, score=(train=0.690, test=0.543) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=random;, score=(train=0.670, test=0.546) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=random;, score=(train=0.848, test=0.830) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=4, max_features=log2, splitter=random;, score=(train=0.850, test=0.860) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.911, test=0.868) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.885, test=0.762) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.925, test=0.907) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.869, test=0.894) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=best;, score=(train=0.719, test=0.699) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.847, test=0.813) total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.763, test=0.505) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.889, test=0.887) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.846, test=0.872) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=5, max_features=sqrt, splitter=random;, score=(train=0.747, test=0.785) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=best;, score=(train=0.847, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=best;, score=(train=0.708, test=0.514) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=best;, score=(train=0.908, test=0.897) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=best;, score=(train=0.733, test=0.649) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=best;, score=(train=0.840, test=0.774) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=random;, score=(train=0.802, test=0.769) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=random;, score=(train=0.830, test=0.752) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=random;, score=(train=0.862, test=0.825) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=random;, score=(train=0.694, test=0.617) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=5, max_features=log2, splitter=random;, score=(train=0.715, test=0.817) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.782, test=0.692) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.888, test=0.743) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.881, test=0.856) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.913, test=0.936) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=best;, score=(train=0.914, test=0.914) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.796, test=0.780) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.456, test=0.619) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.836, test=0.773) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.886, test=0.851) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=6, max_features=sqrt, splitter=random;, score=(train=0.848, test=0.849) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=best;, score=(train=0.890, test=0.868) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=best;, score=(train=0.867, test=0.752) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=best;, score=(train=0.893, test=0.897) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=best;, score=(train=0.885, test=0.904) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=best;, score=(train=0.928, test=0.946) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=random;, score=(train=0.824, test=0.791) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=random;, score=(train=0.835, test=0.743) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=random;, score=(train=0.874, test=0.804) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=random;, score=(train=0.787, test=0.702) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=6, max_features=log2, splitter=random;, score=(train=0.758, test=0.763) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.938, test=0.857) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.930, test=0.857) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.939, test=0.918) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.909, test=0.904) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=best;, score=(train=0.807, test=0.753) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.733, test=0.703) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.772, test=0.695) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.872, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.718, test=0.617) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=7, max_features=sqrt, splitter=random;, score=(train=0.847, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=best;, score=(train=0.881, test=0.835) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=best;, score=(train=0.874, test=0.686) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=best;, score=(train=0.885, test=0.876) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=best;, score=(train=0.937, test=0.862) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=best;, score=(train=0.878, test=0.892) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=random;, score=(train=0.884, test=0.835) total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=random;, score=(train=0.818, test=0.762) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=random;, score=(train=0.806, test=0.835) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=random;, score=(train=0.924, test=0.904) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=7, max_features=log2, splitter=random;, score=(train=0.866, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.938, test=0.868) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.907, test=0.800) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.934, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.922, test=0.894) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=best;, score=(train=0.910, test=0.839) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.743, test=0.670) total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.899, test=0.800) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.850, test=0.825) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.910, test=0.862) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=8, max_features=sqrt, splitter=random;, score=(train=0.799, test=0.806) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=best;, score=(train=0.906, test=0.846) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=best;, score=(train=0.905, test=0.838) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=best;, score=(train=0.909, test=0.835) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=best;, score=(train=0.928, test=0.883) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=best;, score=(train=0.924, test=0.914) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=random;, score=(train=0.904, test=0.835) total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=random;, score=(train=0.929, test=0.790) total time=   0.8s\n",
      "[CV 3/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=random;, score=(train=0.871, test=0.835) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=random;, score=(train=0.894, test=0.894) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=8, max_features=log2, splitter=random;, score=(train=0.853, test=0.828) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.900, test=0.802) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.944, test=0.762) total time=   0.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.935, test=0.887) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.940, test=0.872) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=best;, score=(train=0.928, test=0.903) total time=   0.5s\n",
      "[CV 1/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.828, test=0.780) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.878, test=0.714) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.928, test=0.856) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.906, test=0.830) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=9, max_features=sqrt, splitter=random;, score=(train=0.907, test=0.903) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=best;, score=(train=0.942, test=0.813) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=best;, score=(train=0.929, test=0.790) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=best;, score=(train=0.932, test=0.845) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=best;, score=(train=0.953, test=0.894) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=best;, score=(train=0.920, test=0.849) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=random;, score=(train=0.817, test=0.802) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=random;, score=(train=0.914, test=0.705) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=random;, score=(train=0.928, test=0.856) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=random;, score=(train=0.926, test=0.915) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=9, max_features=log2, splitter=random;, score=(train=0.909, test=0.882) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.942, test=0.890) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.962, test=0.867) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.956, test=0.866) total time=   0.5s\n",
      "[CV 4/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.953, test=0.894) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=best;, score=(train=0.951, test=0.903) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.931, test=0.780) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.943, test=0.790) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.917, test=0.866) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.880, test=0.755) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=10, max_features=sqrt, splitter=random;, score=(train=0.921, test=0.882) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=best;, score=(train=0.932, test=0.846) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=best;, score=(train=0.949, test=0.848) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=best;, score=(train=0.925, test=0.763) total time=   0.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=best;, score=(train=0.951, test=0.883) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=best;, score=(train=0.952, test=0.892) total time=   0.4s\n",
      "[CV 1/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=random;, score=(train=0.904, test=0.857) total time=   0.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=random;, score=(train=0.917, test=0.638) total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=random;, score=(train=0.950, test=0.887) total time=   0.5s\n",
      "[CV 4/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=random;, score=(train=0.879, test=0.840) total time=   0.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=10, max_features=log2, splitter=random;, score=(train=0.845, test=0.720) total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "dt_regressor.find_best_param_dt(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'squared_error',\n",
       " 'max_depth': 9,\n",
       " 'max_features': 'sqrt',\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regressor.dt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_regressor.fit_dt(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8301886792452831"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regressor.my_scoring(dt_regressor.model, df_test.drop(['results_positionOrder'], axis = 1), df_test['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt_regressor</th>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.900052</td>\n",
       "      <td>0.27673</td>\n",
       "      <td>0.415094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  accuracy   recall        f1\n",
       "dt_regressor   0.830189  0.900052  0.27673  0.415094"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dt_regressor.dt_metrics, index = ['dt_regressor'], columns = ['precision', 'accuracy', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRandomFroestRegressor():\n",
    "    def my_scoring(self, model, x, y):\n",
    "\n",
    "        precision = 0\n",
    "        accuracy = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "        for i in x['raceId'].unique():\n",
    "            prediction_df = pd.DataFrame(model.predict(x[x['raceId'] == i]), columns = ['results'])\n",
    "            Y_test = y[x[x['raceId'] == i].index]\n",
    "\n",
    "            \n",
    "            prediction_df['podium'] = Y_test.reset_index(drop = True)\n",
    "            prediction_df['actual'] = prediction_df.podium.map(lambda x: 1 if x in [1, 2, 3] else 0)\n",
    "            prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "            prediction_df.reset_index(inplace = True, drop = True)\n",
    "            prediction_df['predicted'] = prediction_df.index\n",
    "            prediction_df['predicted'] = prediction_df.predicted.map(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "            precision += precision_score(prediction_df.actual, prediction_df.predicted)\n",
    "            accuracy += accuracy_score(prediction_df.actual, prediction_df.predicted)\n",
    "            recall += recall_score(prediction_df.actual, prediction_df.predicted)\n",
    "            f1 += f1_score(prediction_df.actual, prediction_df.predicted)\n",
    "        \n",
    "        self.dt_metrics = {'precision': precision/len(x['raceId'].unique()), 'accuracy': accuracy/len(x['raceId'].unique()), 'recall': recall/len(x['raceId'].unique()), 'f1': f1/len(x['raceId'].unique())}\n",
    "        return precision/len(x['raceId'].unique())\n",
    "\n",
    "    def find_best_param_rf(self, x, y):\n",
    "                \n",
    "            self.x = x\n",
    "            self.y = y\n",
    "    \n",
    "            splitter = customCrossValidation().split(x)\n",
    "            \n",
    "            hyper_params = [{'criterion': [\"squared_error\", \"absolute_error\", \"poisson\"], 'max_depth': [4, 5, 8, 9, 10], 'max_features': ['sqrt', 'log2'], 'n_estimators': [100, 150, 200, 300]}]\n",
    "    \n",
    "            model_rf = RandomForestRegressor()\n",
    "            model_cv = GridSearchCV(estimator=model_rf, param_grid=hyper_params, scoring=self.my_scoring, cv = splitter, return_train_score=True, verbose = 3)\n",
    "            model_cv.fit(x, y)\n",
    "            self.rf_params = model_cv.best_params_\n",
    "\n",
    "    def fit_rf(self, x, y):\n",
    "        model = RandomForestRegressor(**self.rf_params)\n",
    "        model.fit(x, y)\n",
    "        self.model = model\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = CustomRandomFroestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.920, test=0.932) total time=   1.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.919, test=0.897) total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.913, test=0.935) total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.919, test=0.944) total time=   1.2s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.921, test=0.925) total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.918, test=0.920) total time=   1.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.932, test=0.897) total time=   1.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.918, test=0.922) total time=   2.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.920, test=0.958) total time=   1.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.921, test=0.910) total time=   1.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.921, test=0.909) total time=   2.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.922, test=0.912) total time=   2.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.923, test=0.948) total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.920, test=0.958) total time=   2.2s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.921, test=0.925) total time=   2.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.921, test=0.920) total time=   3.6s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.924, test=0.897) total time=   3.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.927, test=0.961) total time=   3.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.919, test=0.944) total time=   3.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=sqrt, n_estimators=300;, score=(train=0.929, test=0.910) total time=   4.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.924, test=0.909) total time=   1.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.924, test=0.897) total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.924, test=0.961) total time=   1.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.928, test=0.944) total time=   1.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=100;, score=(train=0.922, test=0.910) total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=150;, score=(train=0.922, test=0.932) total time=   2.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=150;, score=(train=0.927, test=0.912) total time=   1.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=150;, score=(train=0.926, test=0.935) total time=   1.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=150;, score=(train=0.919, test=0.931) total time=   1.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=150;, score=(train=0.926, test=0.925) total time=   1.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.922, test=0.909) total time=   2.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.926, test=0.897) total time=   2.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.923, test=0.922) total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.911, test=0.917) total time=   2.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=200;, score=(train=0.924, test=0.925) total time=   2.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.922, test=0.920) total time=   3.6s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.921, test=0.882) total time=   3.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.923, test=0.909) total time=   3.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.923, test=0.958) total time=   3.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=4, max_features=log2, n_estimators=300;, score=(train=0.925, test=0.925) total time=   3.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.924, test=0.920) total time=   1.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.925, test=0.912) total time=   1.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.926, test=0.948) total time=   1.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.923, test=0.917) total time=   1.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=100;, score=(train=0.931, test=0.896) total time=   1.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=150;, score=(train=0.924, test=0.920) total time=   2.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=150;, score=(train=0.929, test=0.897) total time=   1.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=150;, score=(train=0.922, test=0.948) total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=150;, score=(train=0.925, test=0.944) total time=   1.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=150;, score=(train=0.930, test=0.925) total time=   1.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.928, test=0.920) total time=   2.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.929, test=0.912) total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.922, test=0.948) total time=   2.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.929, test=0.958) total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=200;, score=(train=0.925, test=0.925) total time=   2.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.924, test=0.920) total time=   3.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.930, test=0.912) total time=   3.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.926, test=0.948) total time=   3.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.923, test=0.958) total time=   3.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=sqrt, n_estimators=300;, score=(train=0.925, test=0.925) total time=   3.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.926, test=0.932) total time=   1.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.933, test=0.912) total time=   1.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.928, test=0.935) total time=   1.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.924, test=0.972) total time=   1.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=100;, score=(train=0.931, test=0.910) total time=   1.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=150;, score=(train=0.924, test=0.909) total time=   2.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=150;, score=(train=0.924, test=0.897) total time=   1.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=150;, score=(train=0.926, test=0.922) total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=150;, score=(train=0.919, test=0.944) total time=   2.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=150;, score=(train=0.923, test=0.910) total time=   1.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.924, test=0.920) total time=   3.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.926, test=0.897) total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.932, test=0.935) total time=   2.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.922, test=0.958) total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=200;, score=(train=0.929, test=0.925) total time=   2.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.927, test=0.920) total time=   4.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.930, test=0.897) total time=   3.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.926, test=0.935) total time=   3.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.927, test=0.931) total time=   3.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=5, max_features=log2, n_estimators=300;, score=(train=0.926, test=0.910) total time=   3.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=100;, score=(train=0.942, test=0.898) total time=   1.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=100;, score=(train=0.944, test=0.926) total time=   1.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=100;, score=(train=0.943, test=0.948) total time=   1.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=100;, score=(train=0.942, test=0.958) total time=   1.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=100;, score=(train=0.953, test=0.910) total time=   1.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=150;, score=(train=0.951, test=0.920) total time=   2.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=150;, score=(train=0.948, test=0.912) total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=150;, score=(train=0.949, test=0.935) total time=   2.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=150;, score=(train=0.945, test=0.958) total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=150;, score=(train=0.948, test=0.925) total time=   2.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=200;, score=(train=0.951, test=0.898) total time=   3.6s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=200;, score=(train=0.949, test=0.926) total time=   3.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=200;, score=(train=0.946, test=0.935) total time=   3.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=200;, score=(train=0.945, test=0.972) total time=   3.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=200;, score=(train=0.946, test=0.910) total time=   6.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=300;, score=(train=0.951, test=0.920) total time=   5.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=300;, score=(train=0.945, test=0.912) total time=   5.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=300;, score=(train=0.948, test=0.935) total time=   4.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=300;, score=(train=0.944, test=0.958) total time=   4.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=sqrt, n_estimators=300;, score=(train=0.945, test=0.910) total time=   4.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=100;, score=(train=0.947, test=0.909) total time=   1.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=100;, score=(train=0.948, test=0.941) total time=   1.6s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=100;, score=(train=0.944, test=0.948) total time=   1.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=100;, score=(train=0.943, test=0.944) total time=   1.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=100;, score=(train=0.951, test=0.910) total time=   1.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=150;, score=(train=0.950, test=0.898) total time=   2.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=150;, score=(train=0.945, test=0.912) total time=   2.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=150;, score=(train=0.949, test=0.935) total time=   2.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=150;, score=(train=0.955, test=0.944) total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=150;, score=(train=0.950, test=0.896) total time=   2.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=200;, score=(train=0.949, test=0.920) total time=   3.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=200;, score=(train=0.946, test=0.912) total time=   3.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=200;, score=(train=0.948, test=0.948) total time=   3.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=200;, score=(train=0.946, test=0.958) total time=   3.2s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=200;, score=(train=0.944, test=0.925) total time=   3.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=300;, score=(train=0.951, test=0.920) total time=   5.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=300;, score=(train=0.946, test=0.926) total time=   4.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=300;, score=(train=0.946, test=0.935) total time=   4.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=300;, score=(train=0.947, test=0.958) total time=   4.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=8, max_features=log2, n_estimators=300;, score=(train=0.949, test=0.896) total time=   4.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=100;, score=(train=0.966, test=0.909) total time=   2.2s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=100;, score=(train=0.959, test=0.912) total time=   1.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=100;, score=(train=0.962, test=0.948) total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=100;, score=(train=0.954, test=0.958) total time=   1.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=100;, score=(train=0.959, test=0.910) total time=   1.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=150;, score=(train=0.960, test=0.920) total time=   3.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=150;, score=(train=0.955, test=0.926) total time=   2.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=150;, score=(train=0.961, test=0.961) total time=   2.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=150;, score=(train=0.955, test=0.958) total time=   2.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=150;, score=(train=0.958, test=0.896) total time=   2.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=200;, score=(train=0.963, test=0.932) total time=   3.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=200;, score=(train=0.956, test=0.926) total time=   3.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=200;, score=(train=0.959, test=0.935) total time=   3.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=200;, score=(train=0.952, test=0.958) total time=   3.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=200;, score=(train=0.959, test=0.896) total time=   3.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=300;, score=(train=0.961, test=0.932) total time=   5.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=300;, score=(train=0.955, test=0.926) total time=   5.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=300;, score=(train=0.956, test=0.935) total time=   5.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=300;, score=(train=0.961, test=0.972) total time=   5.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=sqrt, n_estimators=300;, score=(train=0.959, test=0.896) total time=   4.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=100;, score=(train=0.959, test=0.909) total time=   2.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=100;, score=(train=0.958, test=0.926) total time=   1.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=100;, score=(train=0.962, test=0.948) total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=100;, score=(train=0.959, test=0.958) total time=   1.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.896) total time=   1.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=150;, score=(train=0.963, test=0.909) total time=   3.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=150;, score=(train=0.955, test=0.912) total time=   2.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=150;, score=(train=0.957, test=0.935) total time=   2.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=150;, score=(train=0.953, test=0.958) total time=   2.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=150;, score=(train=0.961, test=0.925) total time=   2.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=200;, score=(train=0.968, test=0.909) total time=   3.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=200;, score=(train=0.954, test=0.926) total time=   3.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=200;, score=(train=0.957, test=0.935) total time=   3.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=200;, score=(train=0.961, test=0.958) total time=   3.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=200;, score=(train=0.964, test=0.925) total time=   3.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=300;, score=(train=0.962, test=0.920) total time=   5.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=300;, score=(train=0.961, test=0.926) total time=   5.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=300;, score=(train=0.959, test=0.948) total time=   5.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=300;, score=(train=0.961, test=0.958) total time=   5.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=9, max_features=log2, n_estimators=300;, score=(train=0.962, test=0.910) total time=   5.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=100;, score=(train=0.971, test=0.920) total time=   2.2s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=100;, score=(train=0.964, test=0.912) total time=   2.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=100;, score=(train=0.968, test=0.948) total time=   2.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=100;, score=(train=0.970, test=0.972) total time=   2.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=100;, score=(train=0.971, test=0.910) total time=   2.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=150;, score=(train=0.970, test=0.920) total time=   3.2s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=150;, score=(train=0.967, test=0.926) total time=   3.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=150;, score=(train=0.971, test=0.948) total time=   3.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=150;, score=(train=0.965, test=0.944) total time=   2.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=150;, score=(train=0.968, test=0.910) total time=   2.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=200;, score=(train=0.974, test=0.909) total time=   4.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=200;, score=(train=0.970, test=0.941) total time=   3.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=200;, score=(train=0.971, test=0.948) total time=   4.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=200;, score=(train=0.969, test=0.972) total time=   3.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=200;, score=(train=0.970, test=0.910) total time=   3.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=300;, score=(train=0.969, test=0.909) total time=   5.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=300;, score=(train=0.965, test=0.926) total time=   5.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=300;, score=(train=0.970, test=0.935) total time=   5.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=300;, score=(train=0.971, test=0.958) total time=   5.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, n_estimators=300;, score=(train=0.971, test=0.896) total time=   5.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=100;, score=(train=0.970, test=0.909) total time=   2.2s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=100;, score=(train=0.969, test=0.912) total time=   1.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=100;, score=(train=0.972, test=0.948) total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=100;, score=(train=0.966, test=0.944) total time=   2.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=100;, score=(train=0.965, test=0.910) total time=   1.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=150;, score=(train=0.970, test=0.920) total time=   3.2s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=150;, score=(train=0.969, test=0.926) total time=   3.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=150;, score=(train=0.968, test=0.948) total time=   3.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=150;, score=(train=0.971, test=0.972) total time=   2.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=150;, score=(train=0.972, test=0.896) total time=   2.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=200;, score=(train=0.973, test=0.932) total time=   4.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=200;, score=(train=0.967, test=0.926) total time=   3.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=200;, score=(train=0.973, test=0.948) total time=   3.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=200;, score=(train=0.966, test=0.958) total time=   3.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=200;, score=(train=0.970, test=0.910) total time=   3.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=300;, score=(train=0.971, test=0.909) total time=   5.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=300;, score=(train=0.964, test=0.926) total time=   5.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=300;, score=(train=0.966, test=0.935) total time=   5.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=300;, score=(train=0.969, test=0.958) total time=   5.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=log2, n_estimators=300;, score=(train=0.971, test=0.925) total time=   5.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.928, test=0.920) total time= 2.1min\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.925, test=0.912) total time= 2.1min\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.921, test=0.935) total time= 2.1min\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.919, test=0.958) total time= 2.2min\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=100;, score=(train=0.930, test=0.925) total time= 2.2min\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.922, test=0.920) total time= 3.2min\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.924, test=0.897) total time= 3.2min\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.927, test=0.948) total time= 3.0min\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.924, test=0.958) total time= 3.2min\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=150;, score=(train=0.926, test=0.925) total time= 3.3min\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.927, test=0.932) total time= 4.0min\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.930, test=0.912) total time= 4.0min\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.923, test=0.948) total time= 4.0min\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=4, max_features=sqrt, n_estimators=200;, score=(train=0.924, test=0.958) total time= 4.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [235], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rf_regressor\u001b[39m.\u001b[39;49mfind_best_param_rf(df_train\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mresults_positionOrder\u001b[39;49m\u001b[39m'\u001b[39;49m], axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m), df_train[\u001b[39m'\u001b[39;49m\u001b[39mresults_positionOrder\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn [233], line 39\u001b[0m, in \u001b[0;36mCustomRandomFroestRegressor.find_best_param_rf\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     37\u001b[0m model_rf \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m     38\u001b[0m model_cv \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel_rf, param_grid\u001b[39m=\u001b[39mhyper_params, scoring\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmy_scoring, cv \u001b[39m=\u001b[39m splitter, return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m model_cv\u001b[39m.\u001b[39;49mfit(x, y)\n\u001b[0;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrf_params \u001b[39m=\u001b[39m model_cv\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    480\u001b[0m )(\n\u001b[0;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    482\u001b[0m         t,\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    484\u001b[0m         X,\n\u001b[0;32m    485\u001b[0m         y,\n\u001b[0;32m    486\u001b[0m         sample_weight,\n\u001b[0;32m    487\u001b[0m         i,\n\u001b[0;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_regressor.find_best_param_rf(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor.rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor.fit_rf(df_train.drop(['results_positionOrder'], axis = 1), df_train['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor.my_scoring(rf_regressor.model, df_test.drop(['results_positionOrder'], axis = 1), df_test['results_positionOrder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.dataframe(rf_regressor.dt_metrics, index = ['rf_regressor'], columns = ['precision', 'accuracy', 'recall', 'f1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "affa1e01f2d63dc644a5d836267b8cc21782c0351696aa19b5d442d7e4c7d376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
