{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>year</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>...</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>statusId</th>\n",
       "      <th>circuit_country</th>\n",
       "      <th>constructor_position</th>\n",
       "      <th>constructor_wins</th>\n",
       "      <th>constructor_nationality</th>\n",
       "      <th>driver_nationality</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>results_positionOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>2019</td>\n",
       "      <td>-1.399483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.305908</td>\n",
       "      <td>-1.891242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164847</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>-1.511226</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012</td>\n",
       "      <td>2019</td>\n",
       "      <td>-1.492647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.305908</td>\n",
       "      <td>-1.891242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177463</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.527107</td>\n",
       "      <td>-1.511226</td>\n",
       "      <td>33</td>\n",
       "      <td>1.527107</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011</td>\n",
       "      <td>2019</td>\n",
       "      <td>-1.652281</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.305908</td>\n",
       "      <td>-1.891242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181965</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609763</td>\n",
       "      <td>-1.511226</td>\n",
       "      <td>33</td>\n",
       "      <td>0.609763</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014</td>\n",
       "      <td>2019</td>\n",
       "      <td>-0.795461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.305908</td>\n",
       "      <td>-1.891242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184939</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.444452</td>\n",
       "      <td>-1.511226</td>\n",
       "      <td>33</td>\n",
       "      <td>2.444452</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>2019</td>\n",
       "      <td>-0.115243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.305908</td>\n",
       "      <td>-1.891242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200219</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.361796</td>\n",
       "      <td>-1.511226</td>\n",
       "      <td>33</td>\n",
       "      <td>3.361796</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>648</td>\n",
       "      <td>1970</td>\n",
       "      <td>-2.106547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>-1.184930</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>-0.177747</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>643</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.487922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.194650</td>\n",
       "      <td>0.115553</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>643</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.487922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>0.372834</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>654</td>\n",
       "      <td>1970</td>\n",
       "      <td>-0.181407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>-0.086398</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>654</td>\n",
       "      <td>1970</td>\n",
       "      <td>-0.181407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141578</td>\n",
       "      <td>0.372834</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.307582</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2386 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      raceId  year  circuitId  weather_warm  weather_cold  weather_dry  \\\n",
       "0       1010  2019  -1.399483           1.0           0.0          0.0   \n",
       "1       1012  2019  -1.492647           0.0           0.0          0.0   \n",
       "2       1011  2019  -1.652281           1.0           0.0          0.0   \n",
       "3       1014  2019  -0.795461           1.0           0.0          0.0   \n",
       "4       1015  2019  -0.115243           0.0           0.0          0.0   \n",
       "...      ...   ...        ...           ...           ...          ...   \n",
       "2381     648  1970  -2.106547           0.0           0.0          0.0   \n",
       "2382     643  1970   0.487922           0.0           0.0          1.0   \n",
       "2383     643  1970   0.487922           0.0           0.0          1.0   \n",
       "2384     654  1970  -0.181407           0.0           0.0          1.0   \n",
       "2385     654  1970  -0.181407           0.0           0.0          1.0   \n",
       "\n",
       "      weather_wet  weather_cloudy  driverId  constructorId  ...  milliseconds  \\\n",
       "0             0.0             0.0 -2.305908      -1.891242  ...      0.164847   \n",
       "1             0.0             1.0 -2.305908      -1.891242  ...      0.177463   \n",
       "2             0.0             0.0 -2.305908      -1.891242  ...      0.181965   \n",
       "3             0.0             0.0 -2.305908      -1.891242  ...      0.184939   \n",
       "4             0.0             1.0 -2.305908      -1.891242  ...      0.200219   \n",
       "...           ...             ...       ...            ...  ...           ...   \n",
       "2381          0.0             1.0  0.141578      -1.184930  ...      1.000000   \n",
       "2382          0.0             0.0  0.194650       0.115553  ...      1.000000   \n",
       "2383          0.0             0.0  0.066005       0.372834  ...      1.000000   \n",
       "2384          0.0             1.0  0.141578      -0.086398  ...      1.000000   \n",
       "2385          0.0             1.0  0.141578       0.372834  ...      1.000000   \n",
       "\n",
       "      statusId  circuit_country  constructor_position  constructor_wins  \\\n",
       "0            1                2                   1.0         -0.307582   \n",
       "1            1                9                   1.0          1.527107   \n",
       "2            1                5                   1.0          0.609763   \n",
       "3            1               28                   1.0          2.444452   \n",
       "4            1               19                   1.0          3.361796   \n",
       "...        ...              ...                   ...               ...   \n",
       "2381         0               10                   7.0         -0.307582   \n",
       "2382         0               27                   5.0         -0.307582   \n",
       "2383         0               27                   1.0         -0.307582   \n",
       "2384         0               34                   6.0         -0.307582   \n",
       "2385         0               34                   4.0         -0.307582   \n",
       "\n",
       "      constructor_nationality  driver_nationality  driver_wins  driver_age  \\\n",
       "0                   -1.511226                  33    -0.307582    0.708333   \n",
       "1                   -1.511226                  33     1.527107    0.708333   \n",
       "2                   -1.511226                  33     0.609763    0.708333   \n",
       "3                   -1.511226                  33     2.444452    0.708333   \n",
       "4                   -1.511226                  33     3.361796    0.708333   \n",
       "...                       ...                 ...          ...         ...   \n",
       "2381                -0.177747                  14    -0.307582    0.458333   \n",
       "2382                 0.055528                  46    -0.307582    1.000000   \n",
       "2383                 0.055528                  27    -0.307582    0.708333   \n",
       "2384                 0.055528                  33    -0.307582    0.625000   \n",
       "2385                 0.055528                  34    -0.307582    0.666667   \n",
       "\n",
       "      results_positionOrder  \n",
       "0                         2  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         1  \n",
       "4                         1  \n",
       "...                     ...  \n",
       "2381                     14  \n",
       "2382                      8  \n",
       "2383                     11  \n",
       "2384                     25  \n",
       "2385                     21  \n",
       "\n",
       "[2386 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv').drop_duplicates()\n",
    "df_test = pd.read_csv('./data/test.csv').drop_duplicates()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "def linearRegression(X_train, Y_train):\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, Y_train)        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Linear_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = linearRegression(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Regression - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def gaussian_NB(X_train, Y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_NB_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = gaussian_NB(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def DTregressor(X_train, Y_train):\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_DT_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = DTregressor(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def RFregressor(X_train, Y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_RF_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = RFregressor(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_scores = {}\n",
    "regression_scores['Linear Regression'] = get_Linear_Regression_Score()\n",
    "regression_scores['NB Regression'] = get_NB_Regression_Score()\n",
    "regression_scores['DT Regression'] = get_DT_Regression_Score()\n",
    "regression_scores['RF Regression'] = get_RF_Regression_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>NB Regression</th>\n",
       "      <th>DT Regression</th>\n",
       "      <th>RF Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.825243</td>\n",
       "      <td>0.893204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.883670</td>\n",
       "      <td>0.882404</td>\n",
       "      <td>0.897058</td>\n",
       "      <td>0.903080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.220065</td>\n",
       "      <td>0.223301</td>\n",
       "      <td>0.275081</td>\n",
       "      <td>0.297735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.330097</td>\n",
       "      <td>0.334951</td>\n",
       "      <td>0.412621</td>\n",
       "      <td>0.446602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Linear Regression  NB Regression  DT Regression  RF Regression\n",
       "Precision           0.660194       0.669903       0.825243       0.893204\n",
       "Accuracy            0.883670       0.882404       0.897058       0.903080\n",
       "Recall              0.220065       0.223301       0.275081       0.297735\n",
       "F1                  0.330097       0.334951       0.412621       0.446602"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(regression_scores, index = ['Precision', 'Accuracy', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logisticRegression(X_train, Y_train):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Logistic_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = logisticRegression(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8737864077669902, 0.901288108224765, 0.2912621359223297, 0.4368932038834951)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train\n",
    "get_Logistic_Regression_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gaussianNB(X_train, Y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Gaussian_NB_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = gaussianNB(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8058252427184466,\n",
       " 0.8955115726424042,\n",
       " 0.2686084142394819,\n",
       " 0.4029126213592233)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Gaussian_NB_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def DT_classifier(X_train, Y_train):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_DT_classifier_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = DT_classifier(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6310679611650486,\n",
       " 0.8805868034892437,\n",
       " 0.2103559870550161,\n",
       " 0.3155339805825243)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_DT_classifier_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def RF_classifier(X_train, Y_train):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_RF_classifier_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = RF_classifier(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8737864077669902, 0.901332626812973, 0.2912621359223297, 0.4368932038834951)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RF_classifier_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classification_scores = {}\n",
    "classification_scores['Logistic Regression'] = get_Logistic_Regression_Score()\n",
    "classification_scores['NB classification'] = get_Gaussian_NB_Score()\n",
    "classification_scores['DT classification'] = get_DT_classifier_Score()\n",
    "classification_scores['RF classification'] = get_RF_classifier_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>NB classification</th>\n",
       "      <th>DT classification</th>\n",
       "      <th>RF classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.873786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.895512</td>\n",
       "      <td>0.885733</td>\n",
       "      <td>0.901185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.268608</td>\n",
       "      <td>0.229773</td>\n",
       "      <td>0.291262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.436893</td>\n",
       "      <td>0.402913</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  NB classification  DT classification  \\\n",
       "Precision             0.873786           0.805825           0.689320   \n",
       "Accuracy              0.901288           0.895512           0.885733   \n",
       "Recall                0.291262           0.268608           0.229773   \n",
       "F1                    0.436893           0.402913           0.344660   \n",
       "\n",
       "           RF classification  \n",
       "Precision           0.873786  \n",
       "Accuracy            0.901185  \n",
       "Recall              0.291262  \n",
       "F1                  0.436893  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_scores, index = ['Precision', 'Accuracy', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "affa1e01f2d63dc644a5d836267b8cc21782c0351696aa19b5d442d7e4c7d376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
