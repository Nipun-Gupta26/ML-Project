{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>year</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>...</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>statusId</th>\n",
       "      <th>circuit_country</th>\n",
       "      <th>constructor_position</th>\n",
       "      <th>constructor_wins</th>\n",
       "      <th>constructor_nationality</th>\n",
       "      <th>driver_nationality</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>results_positionOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.264318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>881</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.224938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>882</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.395410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187334</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>883</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.495754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186830</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>884</td>\n",
       "      <td>2013</td>\n",
       "      <td>-0.691174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671359</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194470</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>567</td>\n",
       "      <td>1976</td>\n",
       "      <td>1.281412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>-0.955050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>571</td>\n",
       "      <td>1976</td>\n",
       "      <td>-0.613072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645484</td>\n",
       "      <td>1.129065</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>563</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.861440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>-0.595194</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>574</td>\n",
       "      <td>1976</td>\n",
       "      <td>-0.072666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>566</td>\n",
       "      <td>1976</td>\n",
       "      <td>1.491559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129289</td>\n",
       "      <td>-0.955050</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.105238</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.310902</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2504 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      raceId  year  circuitId  weather_warm  weather_cold  weather_dry  \\\n",
       "0        880  2013  -1.264318           1.0           0.0          0.0   \n",
       "1        881  2013  -1.224938           0.0           0.0          1.0   \n",
       "2        882  2013  -1.395410           1.0           0.0          0.0   \n",
       "3        883  2013  -1.495754           1.0           0.0          0.0   \n",
       "4        884  2013  -0.691174           1.0           0.0          0.0   \n",
       "...      ...   ...        ...           ...           ...          ...   \n",
       "2499     567  1976   1.281412           1.0           0.0          0.0   \n",
       "2500     571  1976  -0.613072           0.0           0.0          1.0   \n",
       "2501     563  1976   0.861440           1.0           0.0          0.0   \n",
       "2502     574  1976  -0.072666           1.0           0.0          0.0   \n",
       "2503     566  1976   1.491559           0.0           0.0          1.0   \n",
       "\n",
       "      weather_wet  weather_cloudy  driverId  constructorId  ...  milliseconds  \\\n",
       "0             0.0             0.0 -0.671359      -0.965034  ...      0.176079   \n",
       "1             1.0             1.0 -0.671359      -0.965034  ...      1.000000   \n",
       "2             0.0             0.0 -0.671359      -0.965034  ...      0.187334   \n",
       "3             0.0             0.0 -0.671359      -0.965034  ...      0.186830   \n",
       "4             0.0             0.0 -0.671359      -0.965034  ...      0.194470   \n",
       "...           ...             ...       ...            ...  ...           ...   \n",
       "2499          0.0             0.0  0.129289      -0.955050  ...      1.000000   \n",
       "2500          0.0             0.0  0.645484       1.129065  ...      1.000000   \n",
       "2501          0.0             0.0  0.129289      -0.595194  ...      1.000000   \n",
       "2502          0.0             0.0  0.129289       0.043700  ...      1.000000   \n",
       "2503          0.0             0.0  0.129289      -0.955050  ...      1.000000   \n",
       "\n",
       "      statusId  circuit_country  constructor_position  constructor_wins  \\\n",
       "0            1                2                   6.0         -0.310902   \n",
       "1            0               17                   7.0         -0.310902   \n",
       "2            1                9                   5.0         -0.310902   \n",
       "3            1                5                   6.0         -0.310902   \n",
       "4            1               28                   6.0         -0.310902   \n",
       "...        ...              ...                   ...               ...   \n",
       "2499         0               10                  17.0         -0.310902   \n",
       "2500         0               21                  10.0         -0.310902   \n",
       "2501         0               28                  15.0         -0.310902   \n",
       "2502         0               34                  14.0         -0.310902   \n",
       "2503         0               29                  17.0         -0.310902   \n",
       "\n",
       "      constructor_nationality  driver_nationality  driver_wins  driver_age  \\\n",
       "0                    0.105238                  33    -0.310902    0.666667   \n",
       "1                    0.105238                  33    -0.310902    0.666667   \n",
       "2                    0.105238                  33    -0.310902    0.666667   \n",
       "3                    0.105238                  33    -0.310902    0.666667   \n",
       "4                    0.105238                  33    -0.310902    0.666667   \n",
       "...                       ...                 ...          ...         ...   \n",
       "2499                 0.105238                  33    -0.310902    0.541667   \n",
       "2500                 0.105238                  29    -0.310902    0.791667   \n",
       "2501                 0.105238                  28    -0.310902    0.583333   \n",
       "2502                 0.076599                   2    -0.310902    0.375000   \n",
       "2503                 0.105238                  38    -0.310902    0.625000   \n",
       "\n",
       "      results_positionOrder  \n",
       "0                         9  \n",
       "1                        17  \n",
       "2                         5  \n",
       "3                        10  \n",
       "4                         8  \n",
       "...                     ...  \n",
       "2499                     20  \n",
       "2500                     20  \n",
       "2501                     20  \n",
       "2502                     14  \n",
       "2503                     20  \n",
       "\n",
       "[2504 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv').drop_duplicates()\n",
    "df_test = pd.read_csv('./data/test.csv').drop_duplicates()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "def linearRegression(X_train, Y_train):\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, Y_train)        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Linear_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = linearRegression(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def DTregressor(X_train, Y_train):\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_DT_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = DTregressor(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def RFregressor(X_train, Y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_RF_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = RFregressor(X_train, Y_train)\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_scores = {}\n",
    "regression_scores['Linear Regression'] = get_Linear_Regression_Score()\n",
    "regression_scores['DT Regression'] = get_DT_Regression_Score()\n",
    "regression_scores['RF Regression'] = get_RF_Regression_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>DT Regression</th>\n",
       "      <th>RF Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.905660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.890946</td>\n",
       "      <td>0.898529</td>\n",
       "      <td>0.905685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.242138</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.301887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.363208</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.452830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Linear Regression  DT Regression  RF Regression\n",
       "Precision           0.726415       0.820755       0.905660\n",
       "Accuracy            0.890946       0.898529       0.905685\n",
       "Recall              0.242138       0.273585       0.301887\n",
       "F1                  0.363208       0.410377       0.452830"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(regression_scores, index = ['Precision', 'Accuracy', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logisticRegression(X_train, Y_train):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Logistic_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = logisticRegression(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8737864077669902, 0.901288108224765, 0.2912621359223297, 0.4368932038834951)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train\n",
    "get_Logistic_Regression_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gaussianNB(X_train, Y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Gaussian_NB_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = gaussianNB(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8058252427184466,\n",
       " 0.8955115726424042,\n",
       " 0.2686084142394819,\n",
       " 0.4029126213592233)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Gaussian_NB_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def DT_classifier(X_train, Y_train):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_DT_classifier_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = DT_classifier(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6310679611650486,\n",
       " 0.8805868034892437,\n",
       " 0.2103559870550161,\n",
       " 0.3155339805825243)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_DT_classifier_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def RF_classifier(X_train, Y_train):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_RF_classifier_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = RF_classifier(X_train, Y_train.values.ravel())\n",
    "\n",
    "    precision = 0\n",
    "    accuracy = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        precision += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        accuracy += accuracy_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        recall += recall_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "        f1 += f1_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "\n",
    "    return precision/len(df_test['raceId'].unique()), accuracy/len(df_test['raceId'].unique()), recall/len(df_test['raceId'].unique()), f1/len(df_test['raceId'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8737864077669902, 0.901332626812973, 0.2912621359223297, 0.4368932038834951)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RF_classifier_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classification_scores = {}\n",
    "classification_scores['Logistic Regression'] = get_Logistic_Regression_Score()\n",
    "classification_scores['NB classification'] = get_Gaussian_NB_Score()\n",
    "classification_scores['DT classification'] = get_DT_classifier_Score()\n",
    "classification_scores['RF classification'] = get_RF_classifier_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>NB classification</th>\n",
       "      <th>DT classification</th>\n",
       "      <th>RF classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.873786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.895512</td>\n",
       "      <td>0.885733</td>\n",
       "      <td>0.901185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.291262</td>\n",
       "      <td>0.268608</td>\n",
       "      <td>0.229773</td>\n",
       "      <td>0.291262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.436893</td>\n",
       "      <td>0.402913</td>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.436893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic Regression  NB classification  DT classification  \\\n",
       "Precision             0.873786           0.805825           0.689320   \n",
       "Accuracy              0.901288           0.895512           0.885733   \n",
       "Recall                0.291262           0.268608           0.229773   \n",
       "F1                    0.436893           0.402913           0.344660   \n",
       "\n",
       "           RF classification  \n",
       "Precision           0.873786  \n",
       "Accuracy            0.901185  \n",
       "Recall              0.291262  \n",
       "F1                  0.436893  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_scores, index = ['Precision', 'Accuracy', 'Recall', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "affa1e01f2d63dc644a5d836267b8cc21782c0351696aa19b5d442d7e4c7d376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
