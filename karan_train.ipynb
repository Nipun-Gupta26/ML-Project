{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>year</th>\n",
       "      <th>circuitId</th>\n",
       "      <th>weather_warm</th>\n",
       "      <th>weather_cold</th>\n",
       "      <th>weather_dry</th>\n",
       "      <th>weather_wet</th>\n",
       "      <th>weather_cloudy</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>...</th>\n",
       "      <th>milliseconds</th>\n",
       "      <th>statusId</th>\n",
       "      <th>circuit_country</th>\n",
       "      <th>constructor_position</th>\n",
       "      <th>constructor_wins</th>\n",
       "      <th>constructor_nationality</th>\n",
       "      <th>driver_nationality</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>results_positionOrder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1.429235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.851798</td>\n",
       "      <td>-0.883873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180472</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>33</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1.398920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.851798</td>\n",
       "      <td>-0.883873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182133</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>33</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>340</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1.555827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.851798</td>\n",
       "      <td>-0.883873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206682</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.527000</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>33</td>\n",
       "      <td>1.527000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1.721793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.851798</td>\n",
       "      <td>-0.883873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193454</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.830986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.851798</td>\n",
       "      <td>-0.883873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186854</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.527000</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>33</td>\n",
       "      <td>1.527000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>616</td>\n",
       "      <td>1973</td>\n",
       "      <td>-0.150902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153611</td>\n",
       "      <td>1.177792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>614</td>\n",
       "      <td>1973</td>\n",
       "      <td>-0.332844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153611</td>\n",
       "      <td>1.177792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>39</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>606</td>\n",
       "      <td>1973</td>\n",
       "      <td>-0.450273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131847</td>\n",
       "      <td>1.041634</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>607</td>\n",
       "      <td>1973</td>\n",
       "      <td>0.365017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>1.177792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>607</td>\n",
       "      <td>1973</td>\n",
       "      <td>0.365017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154513</td>\n",
       "      <td>0.141488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.310106</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2003 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      raceId  year  circuitId  weather_warm  weather_cold  weather_dry  \\\n",
       "0        338  2010  -1.429235           0.0           0.0          0.0   \n",
       "1        339  2010  -1.398920           0.0           0.0          1.0   \n",
       "2        340  2010  -1.555827           0.0           0.0          0.0   \n",
       "3        337  2010  -1.721793           1.0           0.0          0.0   \n",
       "4        341  2010  -0.830986           0.0           0.0          1.0   \n",
       "...      ...   ...        ...           ...           ...          ...   \n",
       "1998     616  1973  -0.150902           1.0           0.0          0.0   \n",
       "1999     614  1973  -0.332844           0.0           0.0          1.0   \n",
       "2000     606  1973  -0.450273           1.0           0.0          0.0   \n",
       "2001     607  1973   0.365017           0.0           0.0          1.0   \n",
       "2002     607  1973   0.365017           0.0           0.0          1.0   \n",
       "\n",
       "      weather_wet  weather_cloudy  driverId  constructorId  ...  milliseconds  \\\n",
       "0             1.0             1.0 -0.851798      -0.883873  ...      0.180472   \n",
       "1             0.0             0.0 -0.851798      -0.883873  ...      0.182133   \n",
       "2             1.0             0.0 -0.851798      -0.883873  ...      0.206682   \n",
       "3             0.0             0.0 -0.851798      -0.883873  ...      0.193454   \n",
       "4             0.0             0.0 -0.851798      -0.883873  ...      0.186854   \n",
       "...           ...             ...       ...            ...  ...           ...   \n",
       "1998          0.0             0.0  0.153611       1.177792  ...      1.000000   \n",
       "1999          0.0             0.0  0.153611       1.177792  ...      1.000000   \n",
       "2000          0.0             1.0  0.131847       1.041634  ...      1.000000   \n",
       "2001          0.0             0.0  0.440952       1.177792  ...      1.000000   \n",
       "2002          0.0             0.0  0.154513       0.141488  ...      1.000000   \n",
       "\n",
       "      statusId  circuit_country  constructor_position  constructor_wins  \\\n",
       "0            1                2                   2.0          0.608447   \n",
       "1            1               17                   2.0          0.608447   \n",
       "2            1                9                   1.0          1.527000   \n",
       "3            1                5                   2.0         -0.310106   \n",
       "4            1               28                   1.0          1.527000   \n",
       "...        ...              ...                   ...               ...   \n",
       "1998         0                3                  10.0         -0.310106   \n",
       "1999         0               21                   9.0         -0.310106   \n",
       "2000         0                7                   9.0         -0.310106   \n",
       "2001         0               27                   8.0         -0.310106   \n",
       "2002         0               27                   2.0         -0.310106   \n",
       "\n",
       "      constructor_nationality  driver_nationality  driver_wins  driver_age  \\\n",
       "0                    0.044247                  33     0.608447    0.521739   \n",
       "1                    0.044247                  33     0.608447    0.521739   \n",
       "2                    0.044247                  33     1.527000    0.521739   \n",
       "3                    0.044247                  33    -0.310106    0.521739   \n",
       "4                    0.044247                  33     1.527000    0.521739   \n",
       "...                       ...                 ...          ...         ...   \n",
       "1998                 0.044247                  39    -0.310106    0.565217   \n",
       "1999                 0.044247                  39    -0.310106    0.565217   \n",
       "2000                 0.044247                   7    -0.310106    0.782609   \n",
       "2001                 0.044247                  27    -0.310106    0.869565   \n",
       "2002                 0.044247                  27    -0.310106    0.434783   \n",
       "\n",
       "      results_positionOrder  \n",
       "0                         1  \n",
       "1                         8  \n",
       "2                         1  \n",
       "3                         7  \n",
       "4                         5  \n",
       "...                     ...  \n",
       "1998                      9  \n",
       "1999                      6  \n",
       "2000                     12  \n",
       "2001                     18  \n",
       "2002                     13  \n",
       "\n",
       "[2003 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv').drop_duplicates()\n",
    "df_test = pd.read_csv('./data/test.csv').drop_duplicates()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "def linearRegression(X_train, Y_train):\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_train, Y_train)        \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Linear_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = linearRegression(X_train, Y_train)\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Regression - Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def gaussian_NB(X_train, Y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_NB_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = gaussian_NB(X_train, Y_train)\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def DTregressor(X_train, Y_train):\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_DT_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = DTregressor(X_train, Y_train)\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def RFregressor(X_train, Y_train):\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_RF_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder']\n",
    "    model = RFregressor(X_train, Y_train)\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict(X_test), columns = ['results'])\n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results', ascending = True, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)        \n",
    "\n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_scores = {}\n",
    "regression_scores['Linear Regression'] = get_Linear_Regression_Score()\n",
    "regression_scores['NB Regression'] = get_NB_Regression_Score()\n",
    "regression_scores['DT Regression'] = get_DT_Regression_Score()\n",
    "regression_scores['RF Regression'] = get_RF_Regression_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB Regression</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT Regression</td>\n",
       "      <td>0.852273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF Regression</td>\n",
       "      <td>0.920455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  accuracy\n",
       "0  Linear Regression  0.534091\n",
       "1      NB Regression  0.625000\n",
       "2      DT Regression  0.852273\n",
       "3      RF Regression  0.920455"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(regression_scores.items(), columns = ['model', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def logisticRegression(X_train, Y_train):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Logistic_Regression_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = logisticRegression(X_train, Y_train.values.ravel())\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train\n",
    "get_Logistic_Regression_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def gaussianNB(X_train, Y_train):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_Gaussian_NB_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = gaussianNB(X_train, Y_train.values.ravel())\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8295454545454546"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Gaussian_NB_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def DT_classifier(X_train, Y_train):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_DT_classifier_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = DT_classifier(X_train, Y_train.values.ravel())\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6590909090909091"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_DT_classifier_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def RF_classifier(X_train, Y_train):\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def get_RF_classifier_Score():\n",
    "    X_train = df_train.drop(columns = ['results_positionOrder'])\n",
    "    Y_train = df_train['results_positionOrder'].to_frame()    \n",
    "    Y_train['results_positionOrder'] = Y_train['results_positionOrder'].map(lambda x: 1 if x in [1,2,3] else 0)    \n",
    "    model = RF_classifier(X_train, Y_train.values.ravel())\n",
    "\n",
    "    score = 0\n",
    "    for i in df_test['raceId'].unique():\n",
    "        X_test = df_test[df_test['raceId'] == i].drop(columns = ['results_positionOrder'])\n",
    "        Y_test = df_test[df_test['raceId'] == i]['results_positionOrder']\n",
    "\n",
    "        prediction_df = pd.DataFrame(model.predict_proba(X_test), columns = ['results0', 'results1'])        \n",
    "        prediction_df['actual_position'] = Y_test.reset_index(drop = True)\n",
    "        prediction_df['actual_podium'] = prediction_df.actual_position.map(lambda x: 1 if x in [1,2,3] else 0)\n",
    "        prediction_df.sort_values('results1', ascending = False, inplace = True)\n",
    "        prediction_df.reset_index(inplace = True, drop = True)                \n",
    "        prediction_df['predicted_podium'] = prediction_df.index.map(lambda x: 1 if x == 0 else 0)            \n",
    "        # print(prediction_df)            \n",
    "        score += precision_score(prediction_df.actual_podium, prediction_df.predicted_podium)\n",
    "    modelScore = score / df_test['raceId'].nunique()\n",
    "    return modelScore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8977272727272727"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_RF_classifier_Score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling all classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "classification_scores = {}\n",
    "classification_scores['Logistic Regression'] = get_Logistic_Regression_Score()\n",
    "classification_scores['NB classification'] = get_Gaussian_NB_Score()\n",
    "classification_scores['DT classification'] = get_DT_classifier_Score()\n",
    "classification_scores['RF classification'] = get_RF_classifier_Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB classification</td>\n",
       "      <td>0.829545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT classification</td>\n",
       "      <td>0.647727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF classification</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  accuracy\n",
       "0  Logistic Regression  0.863636\n",
       "1    NB classification  0.829545\n",
       "2    DT classification  0.647727\n",
       "3    RF classification  0.909091"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_scores.items(), columns = ['model', 'accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
